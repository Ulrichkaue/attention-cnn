{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1613f92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-21 14:15:55.742676: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-21 14:15:55.742733: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-21 14:15:55.787528: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-21 14:15:55.892749: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-21 14:15:57.026913: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, confusion_matrix\n",
    "import seaborn as sn\n",
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "318ede88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Data Science Academy\n",
      "\n",
      "seaborn    : 0.13.2\n",
      "numpy      : 1.23.5\n",
      "torch      : 2.2.1\n",
      "torchvision: 0.16.2\n",
      "matplotlib : 3.5.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Versões dos pacotes usados neste jupyter notebook\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Data Science Academy\" --iversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "345933b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar 21 14:15:59 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.65                 Driver Version: 551.86         CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3060 Ti     On  |   00000000:09:00.0  On |                  N/A |\n",
      "| 52%   34C    P8             19W /  225W |     564MiB /   8192MiB |     14%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A        27      G   /Xwayland                                   N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "GPU atual: NVIDIA GeForce RTX 3060 Ti\n"
     ]
    }
   ],
   "source": [
    "# Verifica a disponibilidade do uso da GPU (RTX 3060 Ti) para o treinamento do modelo\n",
    "!nvidia-smi\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU atual: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"Sem GPU disponível!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13a3e53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(8499)\n",
    "seed(4899)\n",
    "transform = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
    "                               transforms.RandomRotation(10),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5)),\n",
    "                               transforms.Resize([200,200])]) #128,128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6de3fc05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 5712\n",
      "    Root location: /home/ulr1c8/CUDA_related/Mestrado/Brain_Tumor_MRI_figshare+SARTAJ+Br35H/Training\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               RandomHorizontalFlip(p=0.5)\n",
      "               RandomRotation(degrees=[-10.0, 10.0], interpolation=nearest, expand=False, fill=0)\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
      "               Resize(size=[200, 200], interpolation=bilinear, max_size=None, antialias=True)\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "# Dados de Treino\n",
    "train_data = ImageFolder(root = '/home/ulr1c8/CUDA_related/Mestrado/Brain_Tumor_MRI_figshare+SARTAJ+Br35H/Training', \n",
    "                         transform=transform)\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03bac7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 1311\n",
      "    Root location: /home/ulr1c8/CUDA_related/Mestrado/Brain_Tumor_MRI_figshare+SARTAJ+Br35H/Testing\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               RandomHorizontalFlip(p=0.5)\n",
      "               RandomRotation(degrees=[-10.0, 10.0], interpolation=nearest, expand=False, fill=0)\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
      "               Resize(size=[200, 200], interpolation=bilinear, max_size=None, antialias=True)\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "# Dados de Teste\n",
    "test_data = ImageFolder(root = '/home/ulr1c8/CUDA_related/Mestrado/Brain_Tumor_MRI_figshare+SARTAJ+Br35H/Testing',\n",
    "                       transform=transform)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e116ecea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5712"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Número de amostras de treino\n",
    "num_amostras_treino = len(train_data)\n",
    "num_amostras_treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "822b5cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criamos um índice e o tornamos randômico\n",
    "torch.manual_seed(8499)\n",
    "seed(4899)\n",
    "indices = list(range(num_amostras_treino))\n",
    "np.random.shuffle(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "475242f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentual dos dados de treino que usaremos no dataset de validação\n",
    "valid_size = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19fe5848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora fazemos o split para os dados de treino e validação\n",
    "split = int(np.floor(valid_size * num_amostras_treino))\n",
    "idx_treino, idx_valid = indices[split:], indices[:split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d78ae5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos as amostras de treino\n",
    "amostras_treino = SubsetRandomSampler(idx_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f85c95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos as amostras de validação\n",
    "amostras_valid = SubsetRandomSampler(idx_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4b46fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de subprocessos para carregar os dados\n",
    "num_workers = 0\n",
    "batch_size = 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b103626f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Loader\n",
    "torch.manual_seed(8499)\n",
    "seed(4899)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, \n",
    "                                            batch_size = 28, \n",
    "                                            sampler = amostras_treino, \n",
    "                                            num_workers = num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7946495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader de dados de validação\n",
    "torch.manual_seed(8499)\n",
    "seed(4899)\n",
    "valid_loader = torch.utils.data.DataLoader(train_data, \n",
    "                                           batch_size = 28, \n",
    "                                           sampler = amostras_valid, \n",
    "                                           num_workers = num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d071aead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Loader\n",
    "torch.manual_seed(8499)\n",
    "seed(4899)\n",
    "test_loader = torch.utils.data.DataLoader(test_data,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5373f08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, in_dim1, in_dim2, attn_features, red_size, normalize_attn=True):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "        self.red_size = red_size\n",
    "        self.normalize_attn = normalize_attn\n",
    "        self.W1 = nn.Conv2d(in_channels=in_dim1, out_channels=attn_features, kernel_size=1,padding=\n",
    "0, bias=False)\n",
    "        self.W2 = nn.Conv2d(in_channels=in_dim2, out_channels=attn_features, kernel_size=1,padding=\n",
    "0, bias=False)\n",
    "        self.W3 = nn.Conv2d(in_channels=attn_features, out_channels=1, kernel_size = 1, padding = 0, bias = True)\n",
    "        \n",
    "    def forward(self, l, g):\n",
    "        N, C, W, H = l.size()\n",
    "        l_ = self.W1(l)\n",
    "        g_ = self.W2(g)\n",
    "        \n",
    "        if self.red_size > 1:\n",
    "            g_ = F.interpolate(g_, size = self.red_size, mode = 'bilinear', align_corners=False)\n",
    "        c = self.W3(torch.add(l_, g_))\n",
    "        \n",
    "        # Computa o mapa do attention\n",
    "        if self.normalize_attn:\n",
    "            a = F.softmax(c.view(N,1,-1), dim = 2).view(N,1,W,H)\n",
    "        else:\n",
    "            a = torch.sigmoid(c)\n",
    "    \n",
    "        # Re-weight the local feature\n",
    "        f = torch.mul(a.expand_as(l), l) # batch_size CxWxH\n",
    "    \n",
    "        if self.normalize_attn:\n",
    "            output = f.view(N,C,-1).sum(dim=2) # weighted sum\n",
    "        else:\n",
    "            output = F.adaptive_avg_pool2d(f, (1,1)).view(N,C) # global average pooling\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ede3c386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arquitetura do Modelo\n",
    "class ModeloCNN(nn.Module):\n",
    "    \n",
    "    # Pool1 = batch_size,16,50,50\n",
    "    # Pool2 = batch_size,32,44,44\n",
    "    # Pool3 = batch_size,64,20,20\n",
    "    # Pool4 = batch_size,128,14,14\n",
    "    \n",
    "    # Método construtor\n",
    "    def __init__(self):\n",
    "        super(ModeloCNN, self).__init__()\n",
    "        \n",
    "        # Camada Convolucional de entrada \n",
    "        self.conv1 = nn.Conv2d(3, 16, 4, padding = 1, stride = 2)\n",
    "        \n",
    "        # Camada MaxPooling 1\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=4, stride=2, padding=1)\n",
    "        \n",
    "        # Camada de Dropout 1 (Regularização)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        # Camada Convolucional 2 \n",
    "        self.conv2 = nn.Conv2d(16, 32, 5, padding = 1)\n",
    "        \n",
    "        # Camada MaxPooling 2\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=5, stride=1, padding=0)\n",
    "        \n",
    "        # Camada de Dropout 2 (Regularização)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        # Camada Convolucional 3 \n",
    "        self.conv3 = nn.Conv2d(32, 64, 4, padding = 1, stride = 2)\n",
    "        \n",
    "        # Camada MaxPooling 3\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=3, stride=1, padding=0)\n",
    "        \n",
    "        # Camada de Dropout 3 (Regularização)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        # Camada Convolucional 4\n",
    "        self.conv4 = nn.Conv2d(64, 128, kernel_size = 5, stride = 1, padding = 0)\n",
    "        \n",
    "        # Camada MaxPooling 4\n",
    "        self.maxpool4 = nn.MaxPool2d(kernel_size = 5, stride = 1, padding = 1)\n",
    "        \n",
    "        # Camada de Attention 1\n",
    "        self.Attn1 = AttentionLayer(in_dim1 = 32, in_dim2 = 128, attn_features = 256, normalize_attn = True, red_size = 44)\n",
    "        \n",
    "        # Camada de Attention 2\n",
    "        self.Attn2 = AttentionLayer(in_dim1 = 64, in_dim2 = 128, attn_features = 256, normalize_attn = True, red_size = 20)\n",
    "        \n",
    "        # Camada Totalmente Conectada 1\n",
    "        self.fc1 = nn.Linear(25184, 1000)\n",
    "        \n",
    "        # Camada Totalmente Conectada 2\n",
    "        self.fc2 = nn.Linear(1000, 500)\n",
    "        \n",
    "        # Camada Totalmente Conectada 3\n",
    "        self.fc3 = nn.Linear(500,4)\n",
    "    \n",
    "    # Método Forward\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Adiciona uma camada de ativação Relu para cada camada convolucional\n",
    "        pool1 = self.dropout(self.maxpool1(F.relu(self.conv1(x))))\n",
    "        pool2 = self.dropout(self.maxpool(F.relu(self.conv2(pool1))))\n",
    "        pool3 = self.dropout(self.maxpool3(F.relu(self.conv3(pool2))))\n",
    "        pool4 = self.dropout(self.maxpool4(F.relu(self.conv4(pool3))))\n",
    "        \n",
    "        N, _, _, _ = pool4.size()\n",
    "        \n",
    "        # Faz o \"achatamento\" da matriz resultante da convolução e cria um vetor\n",
    "        g = pool4.view(pool4.size(0), 14*14*128)\n",
    "        \n",
    "        # Camada de Attention 1\n",
    "        g1 = self.Attn1(pool2, pool4)\n",
    "        \n",
    "        # Camada de Attention 2\n",
    "        g2 = self.Attn2(pool3, pool4)\n",
    "        \n",
    "        # Concatenação dos resultados\n",
    "        g_hat = torch.cat((g, g1, g2), dim = 1) # batch_size x C\n",
    "        \n",
    "        # Adiciona uma camada de dropout para regularização\n",
    "        g_hat = self.dropout(g_hat)        \n",
    "        \n",
    "        # Camada Totalmente Conectada 1\n",
    "        out = self.fc1(g_hat)\n",
    "        \n",
    "        # Camada Totalmente Conectada 2\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        # Camada Totalmente Conectada 3 (Previsões do modelo)\n",
    "        out = self.fc3(out)        \n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1dc68a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModeloCNN(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (maxpool1): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
      "  (maxpool): MaxPool2d(kernel_size=5, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (maxpool3): MaxPool2d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv4): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (maxpool4): MaxPool2d(kernel_size=5, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "  (Attn1): AttentionLayer(\n",
      "    (W1): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (W2): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (W3): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (Attn2): AttentionLayer(\n",
      "    (W1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (W2): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (W3): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (fc1): Linear(in_features=25184, out_features=1000, bias=True)\n",
      "  (fc2): Linear(in_features=1000, out_features=500, bias=True)\n",
      "  (fc3): Linear(in_features=500, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Cria o modelo\n",
    "modelo = ModeloCNN()\n",
    "print(modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d9fa4406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Movemos o modelo para a GPU se disponível\n",
    "if torch.cuda.is_available():\n",
    "    modelo.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "70834f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função perda como categorical cross-entrupy\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "91798b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiperparâmetro taxa de aprendizado\n",
    "lr = 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ce91bbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otimizador\n",
    "optimizer = optim.Adam(modelo.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8515e193",
   "metadata": {},
   "source": [
    "## Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2a18d502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de épocas para treinar o modelo\n",
    "num_epochs = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "436ceffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiperparametro para controlar a mudança do erro em validação\n",
    "erro_valid_min = np.Inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "75104df6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60066b1f",
   "metadata": {},
   "source": [
    "### Treinamento do modelo (a execução pode demorar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9494f6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1 \tErro em Treinamento: 0.005978 \tErro em Validação: 0.043767\n",
      "Erro em Validação foi Reduzido (inf --> 0.043767). Salvando o modelo...\n",
      "\n",
      "Epoch: 2 \tErro em Treinamento: 0.002348 \tErro em Validação: 0.043917\n",
      "\n",
      "Epoch: 3 \tErro em Treinamento: 0.003434 \tErro em Validação: 0.036709\n",
      "Erro em Validação foi Reduzido (0.043767 --> 0.036709). Salvando o modelo...\n",
      "\n",
      "Epoch: 4 \tErro em Treinamento: 0.001634 \tErro em Validação: 0.039104\n",
      "\n",
      "Epoch: 5 \tErro em Treinamento: 0.003019 \tErro em Validação: 0.038704\n",
      "\n",
      "Epoch: 6 \tErro em Treinamento: 0.001682 \tErro em Validação: 0.038084\n",
      "\n",
      "Epoch: 7 \tErro em Treinamento: 0.001531 \tErro em Validação: 0.036587\n",
      "Erro em Validação foi Reduzido (0.036709 --> 0.036587). Salvando o modelo...\n",
      "\n",
      "Epoch: 8 \tErro em Treinamento: 0.001190 \tErro em Validação: 0.036736\n",
      "\n",
      "Epoch: 9 \tErro em Treinamento: 0.001844 \tErro em Validação: 0.033888\n",
      "Erro em Validação foi Reduzido (0.036587 --> 0.033888). Salvando o modelo...\n",
      "\n",
      "Epoch: 10 \tErro em Treinamento: 0.001975 \tErro em Validação: 0.036965\n",
      "\n",
      "Epoch: 11 \tErro em Treinamento: 0.002896 \tErro em Validação: 0.038161\n",
      "\n",
      "Epoch: 12 \tErro em Treinamento: 0.004315 \tErro em Validação: 0.033957\n",
      "\n",
      "Epoch: 13 \tErro em Treinamento: 0.001643 \tErro em Validação: 0.037093\n",
      "\n",
      "Epoch: 14 \tErro em Treinamento: 0.002293 \tErro em Validação: 0.038381\n",
      "\n",
      "Epoch: 15 \tErro em Treinamento: 0.003350 \tErro em Validação: 0.034333\n",
      "\n",
      "Epoch: 16 \tErro em Treinamento: 0.001993 \tErro em Validação: 0.034552\n",
      "\n",
      "Epoch: 17 \tErro em Treinamento: 0.000929 \tErro em Validação: 0.034045\n",
      "\n",
      "Epoch: 18 \tErro em Treinamento: 0.002386 \tErro em Validação: 0.030294\n",
      "Erro em Validação foi Reduzido (0.033888 --> 0.030294). Salvando o modelo...\n",
      "\n",
      "Epoch: 19 \tErro em Treinamento: 0.001087 \tErro em Validação: 0.034319\n",
      "\n",
      "Epoch: 20 \tErro em Treinamento: 0.001327 \tErro em Validação: 0.032105\n",
      "\n",
      "Epoch: 21 \tErro em Treinamento: 0.000917 \tErro em Validação: 0.035475\n",
      "\n",
      "Epoch: 22 \tErro em Treinamento: 0.001610 \tErro em Validação: 0.029056\n",
      "Erro em Validação foi Reduzido (0.030294 --> 0.029056). Salvando o modelo...\n",
      "\n",
      "Epoch: 23 \tErro em Treinamento: 0.002234 \tErro em Validação: 0.033737\n",
      "\n",
      "Epoch: 24 \tErro em Treinamento: 0.001529 \tErro em Validação: 0.038412\n",
      "\n",
      "Epoch: 25 \tErro em Treinamento: 0.000761 \tErro em Validação: 0.036372\n",
      "\n",
      "Epoch: 26 \tErro em Treinamento: 0.000725 \tErro em Validação: 0.037933\n",
      "\n",
      "Epoch: 27 \tErro em Treinamento: 0.001551 \tErro em Validação: 0.038181\n",
      "\n",
      "Epoch: 28 \tErro em Treinamento: 0.002927 \tErro em Validação: 0.038051\n",
      "\n",
      "Epoch: 29 \tErro em Treinamento: 0.000493 \tErro em Validação: 0.038912\n",
      "\n",
      "Epoch: 30 \tErro em Treinamento: 0.000694 \tErro em Validação: 0.043016\n",
      "\n",
      "Epoch: 31 \tErro em Treinamento: 0.001135 \tErro em Validação: 0.036820\n",
      "\n",
      "Epoch: 32 \tErro em Treinamento: 0.002370 \tErro em Validação: 0.035832\n",
      "\n",
      "Epoch: 33 \tErro em Treinamento: 0.000436 \tErro em Validação: 0.036184\n",
      "\n",
      "Epoch: 34 \tErro em Treinamento: 0.000721 \tErro em Validação: 0.043545\n",
      "\n",
      "Epoch: 35 \tErro em Treinamento: 0.000559 \tErro em Validação: 0.037317\n",
      "\n",
      "Epoch: 36 \tErro em Treinamento: 0.001109 \tErro em Validação: 0.039248\n",
      "\n",
      "Epoch: 37 \tErro em Treinamento: 0.000686 \tErro em Validação: 0.038502\n",
      "\n",
      "Epoch: 38 \tErro em Treinamento: 0.000396 \tErro em Validação: 0.037184\n",
      "\n",
      "Epoch: 39 \tErro em Treinamento: 0.000586 \tErro em Validação: 0.034974\n",
      "\n",
      "Epoch: 40 \tErro em Treinamento: 0.000908 \tErro em Validação: 0.042219\n",
      "\n",
      "Epoch: 41 \tErro em Treinamento: 0.001294 \tErro em Validação: 0.039090\n",
      "\n",
      "Epoch: 42 \tErro em Treinamento: 0.001503 \tErro em Validação: 0.039847\n",
      "\n",
      "Epoch: 43 \tErro em Treinamento: 0.000898 \tErro em Validação: 0.038690\n",
      "\n",
      "Epoch: 44 \tErro em Treinamento: 0.000750 \tErro em Validação: 0.037231\n",
      "\n",
      "Epoch: 45 \tErro em Treinamento: 0.001249 \tErro em Validação: 0.033673\n",
      "\n",
      "Epoch: 46 \tErro em Treinamento: 0.001577 \tErro em Validação: 0.035079\n",
      "\n",
      "Epoch: 47 \tErro em Treinamento: 0.002974 \tErro em Validação: 0.035742\n",
      "\n",
      "Epoch: 48 \tErro em Treinamento: 0.000916 \tErro em Validação: 0.042152\n",
      "\n",
      "Epoch: 49 \tErro em Treinamento: 0.001002 \tErro em Validação: 0.035805\n",
      "\n",
      "Epoch: 50 \tErro em Treinamento: 0.001354 \tErro em Validação: 0.035383\n",
      "\n",
      "Epoch: 51 \tErro em Treinamento: 0.001348 \tErro em Validação: 0.037653\n",
      "\n",
      "Epoch: 52 \tErro em Treinamento: 0.001265 \tErro em Validação: 0.035908\n",
      "\n",
      "Epoch: 53 \tErro em Treinamento: 0.000577 \tErro em Validação: 0.034853\n",
      "\n",
      "Epoch: 54 \tErro em Treinamento: 0.001698 \tErro em Validação: 0.034996\n",
      "\n",
      "Epoch: 55 \tErro em Treinamento: 0.000686 \tErro em Validação: 0.035311\n",
      "\n",
      "Epoch: 56 \tErro em Treinamento: 0.000359 \tErro em Validação: 0.033846\n",
      "\n",
      "Epoch: 57 \tErro em Treinamento: 0.001271 \tErro em Validação: 0.034533\n",
      "\n",
      "Epoch: 58 \tErro em Treinamento: 0.000715 \tErro em Validação: 0.036713\n",
      "\n",
      "Epoch: 59 \tErro em Treinamento: 0.001042 \tErro em Validação: 0.037821\n",
      "\n",
      "Epoch: 60 \tErro em Treinamento: 0.000399 \tErro em Validação: 0.036333\n",
      "\n",
      "Epoch: 61 \tErro em Treinamento: 0.002257 \tErro em Validação: 0.037383\n",
      "\n",
      "Epoch: 62 \tErro em Treinamento: 0.002099 \tErro em Validação: 0.037028\n",
      "\n",
      "Epoch: 63 \tErro em Treinamento: 0.002458 \tErro em Validação: 0.034775\n",
      "\n",
      "Epoch: 64 \tErro em Treinamento: 0.000356 \tErro em Validação: 0.035738\n",
      "\n",
      "Epoch: 65 \tErro em Treinamento: 0.001333 \tErro em Validação: 0.034317\n",
      "\n",
      "Epoch: 66 \tErro em Treinamento: 0.001375 \tErro em Validação: 0.035160\n",
      "\n",
      "Epoch: 67 \tErro em Treinamento: 0.001426 \tErro em Validação: 0.041512\n",
      "\n",
      "Epoch: 68 \tErro em Treinamento: 0.000365 \tErro em Validação: 0.034489\n",
      "\n",
      "Epoch: 69 \tErro em Treinamento: 0.000921 \tErro em Validação: 0.035223\n",
      "\n",
      "Epoch: 70 \tErro em Treinamento: 0.000249 \tErro em Validação: 0.035631\n",
      "\n",
      "Epoch: 71 \tErro em Treinamento: 0.001484 \tErro em Validação: 0.035133\n",
      "\n",
      "Epoch: 72 \tErro em Treinamento: 0.000714 \tErro em Validação: 0.033221\n",
      "\n",
      "Epoch: 73 \tErro em Treinamento: 0.000263 \tErro em Validação: 0.033270\n",
      "\n",
      "Epoch: 74 \tErro em Treinamento: 0.001409 \tErro em Validação: 0.043465\n",
      "\n",
      "Epoch: 75 \tErro em Treinamento: 0.001213 \tErro em Validação: 0.039163\n",
      "\n",
      "Epoch: 76 \tErro em Treinamento: 0.001343 \tErro em Validação: 0.035160\n",
      "\n",
      "Epoch: 77 \tErro em Treinamento: 0.001546 \tErro em Validação: 0.037585\n",
      "\n",
      "Epoch: 78 \tErro em Treinamento: 0.000390 \tErro em Validação: 0.037967\n",
      "\n",
      "Epoch: 79 \tErro em Treinamento: 0.000132 \tErro em Validação: 0.033931\n",
      "\n",
      "Epoch: 80 \tErro em Treinamento: 0.000550 \tErro em Validação: 0.037641\n",
      "\n",
      "Epoch: 81 \tErro em Treinamento: 0.001084 \tErro em Validação: 0.040092\n",
      "\n",
      "Epoch: 82 \tErro em Treinamento: 0.000769 \tErro em Validação: 0.040907\n",
      "\n",
      "Epoch: 83 \tErro em Treinamento: 0.001167 \tErro em Validação: 0.036054\n",
      "\n",
      "Epoch: 84 \tErro em Treinamento: 0.000399 \tErro em Validação: 0.035300\n",
      "\n",
      "Epoch: 85 \tErro em Treinamento: 0.000772 \tErro em Validação: 0.040227\n",
      "\n",
      "Epoch: 86 \tErro em Treinamento: 0.001226 \tErro em Validação: 0.039305\n",
      "\n",
      "Epoch: 87 \tErro em Treinamento: 0.001312 \tErro em Validação: 0.038332\n",
      "\n",
      "Epoch: 88 \tErro em Treinamento: 0.000754 \tErro em Validação: 0.040565\n",
      "\n",
      "Epoch: 89 \tErro em Treinamento: 0.001131 \tErro em Validação: 0.033531\n",
      "\n",
      "Epoch: 90 \tErro em Treinamento: 0.001333 \tErro em Validação: 0.037423\n",
      "\n",
      "Epoch: 91 \tErro em Treinamento: 0.000152 \tErro em Validação: 0.037735\n",
      "\n",
      "Epoch: 92 \tErro em Treinamento: 0.000358 \tErro em Validação: 0.035477\n",
      "\n",
      "Epoch: 93 \tErro em Treinamento: 0.000361 \tErro em Validação: 0.037568\n",
      "\n",
      "Epoch: 94 \tErro em Treinamento: 0.000724 \tErro em Validação: 0.036242\n",
      "\n",
      "Epoch: 95 \tErro em Treinamento: 0.001509 \tErro em Validação: 0.041830\n",
      "\n",
      "Epoch: 96 \tErro em Treinamento: 0.000141 \tErro em Validação: 0.039801\n",
      "\n",
      "Epoch: 97 \tErro em Treinamento: 0.001544 \tErro em Validação: 0.042709\n",
      "\n",
      "Epoch: 98 \tErro em Treinamento: 0.000431 \tErro em Validação: 0.041694\n",
      "\n",
      "Epoch: 99 \tErro em Treinamento: 0.000171 \tErro em Validação: 0.038247\n",
      "\n",
      "Epoch: 100 \tErro em Treinamento: 0.000507 \tErro em Validação: 0.037949\n",
      "\n",
      "Epoch: 101 \tErro em Treinamento: 0.000434 \tErro em Validação: 0.037366\n",
      "\n",
      "Epoch: 102 \tErro em Treinamento: 0.000529 \tErro em Validação: 0.037056\n",
      "\n",
      "Epoch: 103 \tErro em Treinamento: 0.000550 \tErro em Validação: 0.040960\n",
      "\n",
      "Epoch: 104 \tErro em Treinamento: 0.000892 \tErro em Validação: 0.039270\n",
      "\n",
      "Epoch: 105 \tErro em Treinamento: 0.001195 \tErro em Validação: 0.036826\n",
      "\n",
      "Epoch: 106 \tErro em Treinamento: 0.000972 \tErro em Validação: 0.041077\n",
      "\n",
      "Epoch: 107 \tErro em Treinamento: 0.000162 \tErro em Validação: 0.041293\n",
      "\n",
      "Epoch: 108 \tErro em Treinamento: 0.000633 \tErro em Validação: 0.043022\n",
      "\n",
      "Epoch: 109 \tErro em Treinamento: 0.000625 \tErro em Validação: 0.043109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 110 \tErro em Treinamento: 0.000585 \tErro em Validação: 0.037920\n",
      "\n",
      "Epoch: 111 \tErro em Treinamento: 0.000465 \tErro em Validação: 0.038169\n",
      "\n",
      "Epoch: 112 \tErro em Treinamento: 0.001166 \tErro em Validação: 0.037726\n",
      "\n",
      "Epoch: 113 \tErro em Treinamento: 0.000376 \tErro em Validação: 0.045191\n",
      "\n",
      "Epoch: 114 \tErro em Treinamento: 0.000235 \tErro em Validação: 0.037414\n",
      "\n",
      "Epoch: 115 \tErro em Treinamento: 0.001074 \tErro em Validação: 0.035387\n",
      "\n",
      "Epoch: 116 \tErro em Treinamento: 0.000725 \tErro em Validação: 0.045292\n",
      "\n",
      "Epoch: 117 \tErro em Treinamento: 0.000650 \tErro em Validação: 0.050120\n",
      "\n",
      "Epoch: 118 \tErro em Treinamento: 0.000456 \tErro em Validação: 0.043178\n",
      "\n",
      "Epoch: 119 \tErro em Treinamento: 0.000464 \tErro em Validação: 0.037081\n",
      "\n",
      "Epoch: 120 \tErro em Treinamento: 0.000953 \tErro em Validação: 0.040652\n",
      "\n",
      "Epoch: 121 \tErro em Treinamento: 0.000943 \tErro em Validação: 0.040222\n",
      "\n",
      "Epoch: 122 \tErro em Treinamento: 0.000662 \tErro em Validação: 0.039834\n",
      "\n",
      "Epoch: 123 \tErro em Treinamento: 0.000293 \tErro em Validação: 0.048406\n",
      "\n",
      "Epoch: 124 \tErro em Treinamento: 0.001797 \tErro em Validação: 0.038944\n",
      "\n",
      "Epoch: 125 \tErro em Treinamento: 0.000649 \tErro em Validação: 0.035400\n",
      "\n",
      "Epoch: 126 \tErro em Treinamento: 0.000263 \tErro em Validação: 0.037182\n",
      "\n",
      "Epoch: 127 \tErro em Treinamento: 0.000520 \tErro em Validação: 0.038362\n",
      "\n",
      "Epoch: 128 \tErro em Treinamento: 0.000471 \tErro em Validação: 0.043204\n",
      "\n",
      "Epoch: 129 \tErro em Treinamento: 0.000050 \tErro em Validação: 0.041320\n",
      "\n",
      "Epoch: 130 \tErro em Treinamento: 0.001871 \tErro em Validação: 0.034271\n",
      "\n",
      "Epoch: 131 \tErro em Treinamento: 0.000279 \tErro em Validação: 0.037935\n",
      "\n",
      "Epoch: 132 \tErro em Treinamento: 0.000372 \tErro em Validação: 0.041419\n",
      "\n",
      "Epoch: 133 \tErro em Treinamento: 0.000289 \tErro em Validação: 0.034227\n",
      "\n",
      "Epoch: 134 \tErro em Treinamento: 0.001680 \tErro em Validação: 0.036769\n",
      "\n",
      "Epoch: 135 \tErro em Treinamento: 0.000260 \tErro em Validação: 0.037668\n",
      "\n",
      "Epoch: 136 \tErro em Treinamento: 0.000249 \tErro em Validação: 0.043598\n",
      "\n",
      "Epoch: 137 \tErro em Treinamento: 0.001599 \tErro em Validação: 0.044205\n",
      "\n",
      "Epoch: 138 \tErro em Treinamento: 0.001955 \tErro em Validação: 0.035938\n",
      "\n",
      "Epoch: 139 \tErro em Treinamento: 0.000603 \tErro em Validação: 0.041406\n",
      "\n",
      "Epoch: 140 \tErro em Treinamento: 0.000651 \tErro em Validação: 0.037919\n",
      "\n",
      "Epoch: 141 \tErro em Treinamento: 0.000682 \tErro em Validação: 0.048526\n",
      "\n",
      "Epoch: 142 \tErro em Treinamento: 0.001242 \tErro em Validação: 0.040716\n",
      "\n",
      "Epoch: 143 \tErro em Treinamento: 0.000245 \tErro em Validação: 0.037651\n",
      "\n",
      "Epoch: 144 \tErro em Treinamento: 0.000530 \tErro em Validação: 0.034256\n",
      "\n",
      "Epoch: 145 \tErro em Treinamento: 0.000167 \tErro em Validação: 0.041818\n",
      "\n",
      "Epoch: 146 \tErro em Treinamento: 0.000249 \tErro em Validação: 0.035314\n",
      "\n",
      "Epoch: 147 \tErro em Treinamento: 0.001308 \tErro em Validação: 0.040059\n",
      "\n",
      "Epoch: 148 \tErro em Treinamento: 0.000063 \tErro em Validação: 0.038483\n",
      "\n",
      "Epoch: 149 \tErro em Treinamento: 0.000594 \tErro em Validação: 0.038321\n",
      "\n",
      "Epoch: 150 \tErro em Treinamento: 0.001665 \tErro em Validação: 0.035166\n",
      "\n",
      "Epoch: 151 \tErro em Treinamento: 0.000316 \tErro em Validação: 0.035214\n",
      "\n",
      "Epoch: 152 \tErro em Treinamento: 0.000240 \tErro em Validação: 0.036049\n",
      "\n",
      "Epoch: 153 \tErro em Treinamento: 0.000210 \tErro em Validação: 0.037697\n",
      "\n",
      "Epoch: 154 \tErro em Treinamento: 0.000050 \tErro em Validação: 0.036128\n",
      "\n",
      "Epoch: 155 \tErro em Treinamento: 0.000612 \tErro em Validação: 0.033544\n",
      "\n",
      "Epoch: 156 \tErro em Treinamento: 0.000203 \tErro em Validação: 0.037048\n",
      "\n",
      "Epoch: 157 \tErro em Treinamento: 0.000409 \tErro em Validação: 0.032998\n",
      "\n",
      "Epoch: 158 \tErro em Treinamento: 0.000469 \tErro em Validação: 0.038635\n",
      "\n",
      "Epoch: 159 \tErro em Treinamento: 0.000343 \tErro em Validação: 0.036771\n",
      "\n",
      "Epoch: 160 \tErro em Treinamento: 0.000192 \tErro em Validação: 0.039927\n",
      "\n",
      "Epoch: 161 \tErro em Treinamento: 0.000922 \tErro em Validação: 0.038676\n",
      "\n",
      "Epoch: 162 \tErro em Treinamento: 0.000319 \tErro em Validação: 0.040961\n",
      "\n",
      "Epoch: 163 \tErro em Treinamento: 0.000529 \tErro em Validação: 0.038046\n",
      "\n",
      "Epoch: 164 \tErro em Treinamento: 0.001580 \tErro em Validação: 0.037563\n",
      "\n",
      "Epoch: 165 \tErro em Treinamento: 0.000382 \tErro em Validação: 0.042802\n",
      "\n",
      "Epoch: 166 \tErro em Treinamento: 0.000222 \tErro em Validação: 0.043264\n",
      "\n",
      "Epoch: 167 \tErro em Treinamento: 0.000169 \tErro em Validação: 0.044907\n",
      "\n",
      "Epoch: 168 \tErro em Treinamento: 0.000275 \tErro em Validação: 0.040910\n",
      "\n",
      "Epoch: 169 \tErro em Treinamento: 0.000539 \tErro em Validação: 0.039667\n",
      "\n",
      "Epoch: 170 \tErro em Treinamento: 0.000726 \tErro em Validação: 0.038092\n",
      "\n",
      "Epoch: 171 \tErro em Treinamento: 0.000664 \tErro em Validação: 0.037421\n",
      "\n",
      "Epoch: 172 \tErro em Treinamento: 0.000288 \tErro em Validação: 0.044588\n",
      "\n",
      "Epoch: 173 \tErro em Treinamento: 0.001958 \tErro em Validação: 0.041165\n",
      "\n",
      "Epoch: 174 \tErro em Treinamento: 0.001094 \tErro em Validação: 0.040805\n",
      "\n",
      "Epoch: 175 \tErro em Treinamento: 0.000157 \tErro em Validação: 0.040165\n",
      "\n",
      "Epoch: 176 \tErro em Treinamento: 0.001706 \tErro em Validação: 0.043276\n",
      "\n",
      "Epoch: 177 \tErro em Treinamento: 0.000779 \tErro em Validação: 0.040971\n",
      "\n",
      "Epoch: 178 \tErro em Treinamento: 0.000432 \tErro em Validação: 0.043669\n",
      "\n",
      "Epoch: 179 \tErro em Treinamento: 0.000117 \tErro em Validação: 0.038488\n",
      "\n",
      "Epoch: 180 \tErro em Treinamento: 0.000558 \tErro em Validação: 0.046720\n",
      "\n",
      "Epoch: 181 \tErro em Treinamento: 0.000389 \tErro em Validação: 0.039678\n",
      "\n",
      "Epoch: 182 \tErro em Treinamento: 0.000235 \tErro em Validação: 0.038671\n",
      "\n",
      "Epoch: 183 \tErro em Treinamento: 0.000104 \tErro em Validação: 0.043145\n",
      "\n",
      "Epoch: 184 \tErro em Treinamento: 0.000408 \tErro em Validação: 0.039810\n",
      "\n",
      "Epoch: 185 \tErro em Treinamento: 0.000096 \tErro em Validação: 0.036975\n",
      "\n",
      "Epoch: 186 \tErro em Treinamento: 0.000686 \tErro em Validação: 0.039803\n",
      "\n",
      "Epoch: 187 \tErro em Treinamento: 0.000767 \tErro em Validação: 0.043845\n",
      "\n",
      "Epoch: 188 \tErro em Treinamento: 0.000130 \tErro em Validação: 0.038247\n",
      "\n",
      "Epoch: 189 \tErro em Treinamento: 0.000141 \tErro em Validação: 0.043851\n",
      "\n",
      "Epoch: 190 \tErro em Treinamento: 0.000836 \tErro em Validação: 0.038851\n",
      "\n",
      "Epoch: 191 \tErro em Treinamento: 0.000136 \tErro em Validação: 0.039136\n",
      "\n",
      "Epoch: 192 \tErro em Treinamento: 0.000629 \tErro em Validação: 0.046496\n",
      "\n",
      "Epoch: 193 \tErro em Treinamento: 0.000258 \tErro em Validação: 0.040266\n",
      "\n",
      "Epoch: 194 \tErro em Treinamento: 0.000282 \tErro em Validação: 0.042383\n",
      "\n",
      "Epoch: 195 \tErro em Treinamento: 0.000368 \tErro em Validação: 0.043758\n",
      "\n",
      "Epoch: 196 \tErro em Treinamento: 0.000397 \tErro em Validação: 0.045070\n",
      "\n",
      "Epoch: 197 \tErro em Treinamento: 0.000344 \tErro em Validação: 0.039266\n",
      "\n",
      "Epoch: 198 \tErro em Treinamento: 0.000497 \tErro em Validação: 0.043802\n",
      "\n",
      "Epoch: 199 \tErro em Treinamento: 0.000244 \tErro em Validação: 0.047013\n",
      "\n",
      "Epoch: 200 \tErro em Treinamento: 0.000121 \tErro em Validação: 0.043127\n",
      "\n",
      "Epoch: 201 \tErro em Treinamento: 0.000088 \tErro em Validação: 0.042356\n",
      "\n",
      "Epoch: 202 \tErro em Treinamento: 0.000339 \tErro em Validação: 0.047727\n",
      "\n",
      "Epoch: 203 \tErro em Treinamento: 0.000104 \tErro em Validação: 0.046297\n",
      "\n",
      "Epoch: 204 \tErro em Treinamento: 0.000103 \tErro em Validação: 0.040643\n",
      "\n",
      "Epoch: 205 \tErro em Treinamento: 0.000329 \tErro em Validação: 0.041984\n",
      "\n",
      "Epoch: 206 \tErro em Treinamento: 0.000052 \tErro em Validação: 0.042686\n",
      "\n",
      "Epoch: 207 \tErro em Treinamento: 0.000115 \tErro em Validação: 0.032800\n",
      "\n",
      "Epoch: 208 \tErro em Treinamento: 0.000225 \tErro em Validação: 0.040290\n",
      "\n",
      "Epoch: 209 \tErro em Treinamento: 0.000340 \tErro em Validação: 0.050745\n",
      "\n",
      "Epoch: 210 \tErro em Treinamento: 0.000263 \tErro em Validação: 0.038591\n",
      "\n",
      "Epoch: 211 \tErro em Treinamento: 0.000061 \tErro em Validação: 0.041745\n",
      "\n",
      "Epoch: 212 \tErro em Treinamento: 0.000310 \tErro em Validação: 0.054119\n",
      "\n",
      "Epoch: 213 \tErro em Treinamento: 0.000147 \tErro em Validação: 0.050052\n",
      "\n",
      "Epoch: 214 \tErro em Treinamento: 0.000135 \tErro em Validação: 0.046049\n",
      "\n",
      "Epoch: 215 \tErro em Treinamento: 0.001778 \tErro em Validação: 0.049543\n",
      "\n",
      "Epoch: 216 \tErro em Treinamento: 0.000275 \tErro em Validação: 0.052507\n",
      "\n",
      "Epoch: 217 \tErro em Treinamento: 0.000094 \tErro em Validação: 0.046344\n",
      "\n",
      "Epoch: 218 \tErro em Treinamento: 0.000332 \tErro em Validação: 0.038419\n",
      "\n",
      "Epoch: 219 \tErro em Treinamento: 0.000229 \tErro em Validação: 0.044025\n",
      "\n",
      "Epoch: 220 \tErro em Treinamento: 0.000372 \tErro em Validação: 0.045534\n",
      "\n",
      "Epoch: 221 \tErro em Treinamento: 0.000101 \tErro em Validação: 0.046510\n",
      "\n",
      "Epoch: 222 \tErro em Treinamento: 0.000211 \tErro em Validação: 0.048402\n",
      "\n",
      "Epoch: 223 \tErro em Treinamento: 0.000949 \tErro em Validação: 0.040859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 224 \tErro em Treinamento: 0.000113 \tErro em Validação: 0.040241\n",
      "\n",
      "Epoch: 225 \tErro em Treinamento: 0.000241 \tErro em Validação: 0.044708\n",
      "\n",
      "Epoch: 226 \tErro em Treinamento: 0.000028 \tErro em Validação: 0.045934\n",
      "\n",
      "Epoch: 227 \tErro em Treinamento: 0.000397 \tErro em Validação: 0.042084\n",
      "\n",
      "Epoch: 228 \tErro em Treinamento: 0.000984 \tErro em Validação: 0.045188\n",
      "\n",
      "Epoch: 229 \tErro em Treinamento: 0.001141 \tErro em Validação: 0.047559\n",
      "\n",
      "Epoch: 230 \tErro em Treinamento: 0.000033 \tErro em Validação: 0.043430\n",
      "\n",
      "Epoch: 231 \tErro em Treinamento: 0.000742 \tErro em Validação: 0.044825\n",
      "\n",
      "Epoch: 232 \tErro em Treinamento: 0.000291 \tErro em Validação: 0.044045\n",
      "\n",
      "Epoch: 233 \tErro em Treinamento: 0.000074 \tErro em Validação: 0.047885\n",
      "\n",
      "Epoch: 234 \tErro em Treinamento: 0.000250 \tErro em Validação: 0.042088\n",
      "\n",
      "Epoch: 235 \tErro em Treinamento: 0.001186 \tErro em Validação: 0.046956\n",
      "\n",
      "Epoch: 236 \tErro em Treinamento: 0.000315 \tErro em Validação: 0.039282\n",
      "\n",
      "Epoch: 237 \tErro em Treinamento: 0.000249 \tErro em Validação: 0.045235\n",
      "\n",
      "Epoch: 238 \tErro em Treinamento: 0.000615 \tErro em Validação: 0.045593\n",
      "\n",
      "Epoch: 239 \tErro em Treinamento: 0.000351 \tErro em Validação: 0.048606\n",
      "\n",
      "Epoch: 240 \tErro em Treinamento: 0.000137 \tErro em Validação: 0.043310\n",
      "\n",
      "Epoch: 241 \tErro em Treinamento: 0.000226 \tErro em Validação: 0.042458\n",
      "\n",
      "Epoch: 242 \tErro em Treinamento: 0.000988 \tErro em Validação: 0.035227\n",
      "\n",
      "Epoch: 243 \tErro em Treinamento: 0.000517 \tErro em Validação: 0.042653\n",
      "\n",
      "Epoch: 244 \tErro em Treinamento: 0.000523 \tErro em Validação: 0.043931\n",
      "\n",
      "Epoch: 245 \tErro em Treinamento: 0.000719 \tErro em Validação: 0.048377\n",
      "\n",
      "Epoch: 246 \tErro em Treinamento: 0.000279 \tErro em Validação: 0.051335\n",
      "\n",
      "Epoch: 247 \tErro em Treinamento: 0.000138 \tErro em Validação: 0.048714\n",
      "\n",
      "Epoch: 248 \tErro em Treinamento: 0.000151 \tErro em Validação: 0.051268\n",
      "\n",
      "Epoch: 249 \tErro em Treinamento: 0.000156 \tErro em Validação: 0.049707\n",
      "\n",
      "Epoch: 250 \tErro em Treinamento: 0.000855 \tErro em Validação: 0.047420\n",
      "\n",
      "Epoch: 251 \tErro em Treinamento: 0.000715 \tErro em Validação: 0.052026\n",
      "\n",
      "Epoch: 252 \tErro em Treinamento: 0.000354 \tErro em Validação: 0.045425\n",
      "\n",
      "Epoch: 253 \tErro em Treinamento: 0.000098 \tErro em Validação: 0.047113\n",
      "\n",
      "Epoch: 254 \tErro em Treinamento: 0.000053 \tErro em Validação: 0.046005\n",
      "\n",
      "Epoch: 255 \tErro em Treinamento: 0.000359 \tErro em Validação: 0.052249\n",
      "\n",
      "Epoch: 256 \tErro em Treinamento: 0.000431 \tErro em Validação: 0.046624\n",
      "\n",
      "Epoch: 257 \tErro em Treinamento: 0.000251 \tErro em Validação: 0.042447\n",
      "\n",
      "Epoch: 258 \tErro em Treinamento: 0.000261 \tErro em Validação: 0.041284\n",
      "\n",
      "Epoch: 259 \tErro em Treinamento: 0.000122 \tErro em Validação: 0.040208\n",
      "\n",
      "Epoch: 260 \tErro em Treinamento: 0.000486 \tErro em Validação: 0.042160\n",
      "\n",
      "Epoch: 261 \tErro em Treinamento: 0.000171 \tErro em Validação: 0.040782\n",
      "\n",
      "Epoch: 262 \tErro em Treinamento: 0.000537 \tErro em Validação: 0.040294\n",
      "\n",
      "Epoch: 263 \tErro em Treinamento: 0.000121 \tErro em Validação: 0.041498\n",
      "\n",
      "Epoch: 264 \tErro em Treinamento: 0.000077 \tErro em Validação: 0.040903\n",
      "\n",
      "Epoch: 265 \tErro em Treinamento: 0.000895 \tErro em Validação: 0.045458\n",
      "\n",
      "Epoch: 266 \tErro em Treinamento: 0.000632 \tErro em Validação: 0.044888\n",
      "\n",
      "Epoch: 267 \tErro em Treinamento: 0.000799 \tErro em Validação: 0.053016\n",
      "\n",
      "Epoch: 268 \tErro em Treinamento: 0.000172 \tErro em Validação: 0.046293\n",
      "\n",
      "Epoch: 269 \tErro em Treinamento: 0.000300 \tErro em Validação: 0.043783\n",
      "\n",
      "Epoch: 270 \tErro em Treinamento: 0.000875 \tErro em Validação: 0.042484\n",
      "\n",
      "Epoch: 271 \tErro em Treinamento: 0.000158 \tErro em Validação: 0.045375\n",
      "\n",
      "Epoch: 272 \tErro em Treinamento: 0.000465 \tErro em Validação: 0.044176\n",
      "\n",
      "Epoch: 273 \tErro em Treinamento: 0.000066 \tErro em Validação: 0.042047\n",
      "\n",
      "Epoch: 274 \tErro em Treinamento: 0.000097 \tErro em Validação: 0.052805\n",
      "\n",
      "Epoch: 275 \tErro em Treinamento: 0.000334 \tErro em Validação: 0.046690\n",
      "\n",
      "Epoch: 276 \tErro em Treinamento: 0.000875 \tErro em Validação: 0.043713\n",
      "\n",
      "Epoch: 277 \tErro em Treinamento: 0.000265 \tErro em Validação: 0.044587\n",
      "\n",
      "Epoch: 278 \tErro em Treinamento: 0.000494 \tErro em Validação: 0.040569\n",
      "\n",
      "Epoch: 279 \tErro em Treinamento: 0.000444 \tErro em Validação: 0.048723\n",
      "\n",
      "Epoch: 280 \tErro em Treinamento: 0.000176 \tErro em Validação: 0.041130\n",
      "\n",
      "Epoch: 281 \tErro em Treinamento: 0.000037 \tErro em Validação: 0.046267\n",
      "\n",
      "Epoch: 282 \tErro em Treinamento: 0.000193 \tErro em Validação: 0.040711\n",
      "\n",
      "Epoch: 283 \tErro em Treinamento: 0.000315 \tErro em Validação: 0.043648\n",
      "\n",
      "Epoch: 284 \tErro em Treinamento: 0.000058 \tErro em Validação: 0.046060\n",
      "\n",
      "Epoch: 285 \tErro em Treinamento: 0.000090 \tErro em Validação: 0.042256\n",
      "\n",
      "Epoch: 286 \tErro em Treinamento: 0.000362 \tErro em Validação: 0.048746\n",
      "\n",
      "Epoch: 287 \tErro em Treinamento: 0.000013 \tErro em Validação: 0.050120\n",
      "\n",
      "Epoch: 288 \tErro em Treinamento: 0.000040 \tErro em Validação: 0.044023\n",
      "\n",
      "Epoch: 289 \tErro em Treinamento: 0.000018 \tErro em Validação: 0.045827\n",
      "\n",
      "Epoch: 290 \tErro em Treinamento: 0.000853 \tErro em Validação: 0.044754\n",
      "\n",
      "Epoch: 291 \tErro em Treinamento: 0.000171 \tErro em Validação: 0.043781\n",
      "\n",
      "Epoch: 292 \tErro em Treinamento: 0.000353 \tErro em Validação: 0.044844\n",
      "\n",
      "Epoch: 293 \tErro em Treinamento: 0.000186 \tErro em Validação: 0.046551\n",
      "\n",
      "Epoch: 294 \tErro em Treinamento: 0.000457 \tErro em Validação: 0.048637\n",
      "\n",
      "Epoch: 295 \tErro em Treinamento: 0.000027 \tErro em Validação: 0.041082\n",
      "\n",
      "Epoch: 296 \tErro em Treinamento: 0.000119 \tErro em Validação: 0.048697\n",
      "\n",
      "Epoch: 297 \tErro em Treinamento: 0.000039 \tErro em Validação: 0.044348\n",
      "\n",
      "Epoch: 298 \tErro em Treinamento: 0.000432 \tErro em Validação: 0.038207\n",
      "\n",
      "Epoch: 299 \tErro em Treinamento: 0.000055 \tErro em Validação: 0.042904\n",
      "\n",
      "Epoch: 300 \tErro em Treinamento: 0.000218 \tErro em Validação: 0.044636\n",
      "CPU times: user 8h 30min 39s, sys: 2min 11s, total: 8h 32min 51s\n",
      "Wall time: 1h 24min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "torch.manual_seed(8499)\n",
    "seed(8499)\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "\n",
    "    # Parâmetros para acompanhar o erro total em treinamento e validação\n",
    "    erro_treino = 0.0\n",
    "    erro_valid = 0.0\n",
    "    \n",
    "    # Inicia o treinamento do modelo\n",
    "    modelo.train().cuda()\n",
    "    \n",
    "    # Loop pelos batches de dados de treino\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        \n",
    "        # Move os tensores para a GPU se disponível\n",
    "        if torch.cuda.is_available():\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        \n",
    "        # Limpa os gradientes de todas as variáveis otimizadas\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward: calcula as saídas previstas\n",
    "        output = modelo(data)\n",
    "        \n",
    "        # Calcula o erro no batch\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        # Backward: calcula o gradiente da perda em relação aos parâmetros do modelo\n",
    "        loss.backward()\n",
    "        \n",
    "        # Realiza uma única etapa de otimização (atualização dos parâmetros)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Atualiza o erro total em treino\n",
    "        erro_treino += loss.item() * data.size(0)\n",
    "        \n",
    "    # Inicia a validação do modelo\n",
    "    modelo.eval().cuda()\n",
    "    \n",
    "    # Loop pelos batches de dados de validação\n",
    "    for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "        \n",
    "        # Move os tensores para a GPU se disponível\n",
    "        if torch.cuda.is_available():\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        \n",
    "        # Forward: calcula as saídas previstas\n",
    "        output = modelo(data)\n",
    "        \n",
    "        # Calcula o erro no batch\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        # Atualiza o erro total de validação\n",
    "        erro_valid += loss.item() * data.size(0)\n",
    "    \n",
    "    # Calcula o erro médio\n",
    "    erro_treino = erro_treino / len(train_loader.dataset)\n",
    "    erro_valid = erro_valid / len(valid_loader.dataset)\n",
    "        \n",
    "    # Print\n",
    "    print('\\nEpoch: {} \\tErro em Treinamento: {:.6f} \\tErro em Validação: {:.6f}'.format(epoch, \n",
    "                                                                                         erro_treino, \n",
    "                                                                                         erro_valid))\n",
    "    \n",
    "    # Salva o modelo sempre que a perda em validação diminuir\n",
    "    if erro_valid <= erro_valid_min:\n",
    "        print('Erro em Validação foi Reduzido ({:.6f} --> {:.6f}). Salvando o modelo...'.format(erro_valid_min,\n",
    "                                                                                                 erro_valid))\n",
    "        pickle.dump(modelo, open('modelo_torch_attn2.pkl', 'wb'))\n",
    "        erro_valid_min = erro_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ded4b45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o modelo com menor erro de validação após treinamanto\n",
    "modelo = pickle.load(open('modelo_torch_attn2.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b77a2c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Só usar caso a acurácia do modelo testado seja maior que a acurácia atual do arquivo modelo_torch.pkl\n",
    "#pickle.dump(modelo, open('modelo_torch_attn.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1c9aac",
   "metadata": {},
   "source": [
    "### Testando e Avaliando o Modelo Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "19484801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de classes das imagens\n",
    "classes = ['glioma', 'meningioma', 'notumor', 'pituitary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "104fafb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erro em teste\n",
    "erro_teste = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f453478a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Controle de acertos do modelo\n",
    "class_correct = list(0. for i in range(4))\n",
    "class_total = list(0. for i in range(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c1f89bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Erro em Teste: 0.072035\n",
      "\n",
      "Acurácia em Teste da classe glioma: 98% (294/300)\n",
      "Acurácia em Teste da classe meningioma: 96% (294/306)\n",
      "Acurácia em Teste da classe notumor: 100% (405/405)\n",
      "Acurácia em Teste da classe pituitary: 99% (298/300)\n",
      "\n",
      "Acurácia em Teste (Total): 98.47% (1291/1311)\n",
      "\n",
      "Matriz de Confusão do Modelo com Camadas de Attention:\n",
      "[[294   5   0   1]\n",
      " [  2 294   5   5]\n",
      " [  0   0 405   0]\n",
      " [  1   1   0 298]]\n",
      "\n",
      "\n",
      "CPU times: user 22.9 s, sys: 138 ms, total: 23 s\n",
      "Wall time: 3.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "torch.manual_seed(8499)\n",
    "seed(4899)\n",
    "\n",
    "prediction = torch.Tensor()\n",
    "prediction = prediction.cuda()\n",
    "y_test = torch.Tensor()\n",
    "y_test = y_test.cuda()\n",
    "\n",
    "torch.manual_seed(8499)\n",
    "seed(8499)\n",
    "\n",
    "# Lista de classes das imagens\n",
    "classes = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
    "\n",
    "# Erro em teste\n",
    "erro_teste = 0.0\n",
    "\n",
    "# Controle de acertos do modelo\n",
    "class_correct = list(0. for i in range(4))\n",
    "class_total = list(0. for i in range(4))\n",
    "\n",
    "# Inicia a avaliação do modelo\n",
    "modelo.eval()\n",
    "\n",
    "# Loop pelos batches de dados de teste\n",
    "for batch_idx, (data, target) in enumerate(test_loader):\n",
    "    \n",
    "    # Move os tensores para GPU se disponível\n",
    "    if torch.cuda.is_available():\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "        y_test = torch.cat((y_test, target), 0)\n",
    "    \n",
    "    # Forward\n",
    "    output = modelo(data)\n",
    "    \n",
    "    # Calcula o erro\n",
    "    loss = criterion(output, target)\n",
    "    \n",
    "    # Atualiza o erro em teste\n",
    "    erro_teste += loss.item() * data.size(0)\n",
    "    \n",
    "    # Converte probabilidades de saída em classe prevista\n",
    "    _, pred = torch.max(output, 1)\n",
    "    prediction = torch.cat((prediction, pred), 0)\n",
    "    \n",
    "    # Compara as previsões com o rótulo verdadeiro\n",
    "    correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not torch.cuda.is_available() else np.squeeze(correct_tensor.cpu().numpy())\n",
    "    \n",
    "    # Calcula a precisão do teste para cada classe\n",
    "    for i in range(batch_size):\n",
    "        label = target.data[i]\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] += 1\n",
    "\n",
    "# Erro médio em teste\n",
    "erro_teste = erro_teste / len(test_loader.dataset)\n",
    "print('\\nErro em Teste: {:.6f}\\n'.format(erro_teste))\n",
    "\n",
    "# Calcula a acurácia para cada classe\n",
    "for i in range(4):\n",
    "    if class_total[i] > 0:\n",
    "        print('Acurácia em Teste da classe %5s: %2d%% (%2d/%2d)' % (classes[i], \n",
    "                                                             100 * class_correct[i] / class_total[i],\n",
    "                                                             np.sum(class_correct[i]), \n",
    "                                                             np.sum(class_total[i])))\n",
    "    else:\n",
    "        print('Acurácia em Teste de %5s:)' % (classes[i]))\n",
    "\n",
    "# Calcula a acurácia total\n",
    "print('\\nAcurácia em Teste (Total): %.2f%% (%2d/%2d)' % (100. * np.sum(class_correct) / np.sum(class_total),\n",
    "                                                        np.sum(class_correct), \n",
    "                                                        np.sum(class_total)))\n",
    "\n",
    "y_test = y_test.cpu()\n",
    "prediction = prediction.cpu()\n",
    "cf_matrix = confusion_matrix(y_test, prediction)\n",
    "print(\"\\nMatriz de Confusão do Modelo com Camadas de Attention:\")\n",
    "print(cf_matrix)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200bf427",
   "metadata": {},
   "source": [
    "## Teste do modelo atual (modelo_torch_attn) {modelo com a melhor acurácia atual}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e0294b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, in_dim1, in_dim2, attn_features, red_size, normalize_attn=True):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "        self.red_size = red_size\n",
    "        self.normalize_attn = normalize_attn\n",
    "        self.W1 = nn.Conv2d(in_channels=in_dim1, out_channels=attn_features, kernel_size=1,padding=\n",
    "0, bias=False)\n",
    "        self.W2 = nn.Conv2d(in_channels=in_dim2, out_channels=attn_features, kernel_size=1,padding=\n",
    "0, bias=False)\n",
    "        self.W3 = nn.Conv2d(in_channels=attn_features, out_channels=1, kernel_size = 1, padding = 0, bias = True)\n",
    "        \n",
    "    def forward(self, l, g):\n",
    "        N, C, W, H = l.size()\n",
    "        l_ = self.W1(l)\n",
    "        g_ = self.W2(g)\n",
    "        \n",
    "        if self.red_size > 1:\n",
    "            g_ = F.interpolate(g_, size = self.red_size, mode = 'bilinear', align_corners=False)\n",
    "        c = self.W3(torch.add(l_, g_))\n",
    "        \n",
    "        # Computa o mapa do attention\n",
    "        if self.normalize_attn:\n",
    "            a = F.softmax(c.view(N,1,-1), dim = 2).view(N,1,W,H)\n",
    "        else:\n",
    "            a = torch.sigmoid(c)\n",
    "    \n",
    "        # Re-weight the local feature\n",
    "        f = torch.mul(a.expand_as(l), l) # batch_size CxWxH\n",
    "    \n",
    "        if self.normalize_attn:\n",
    "            output = f.view(N,C,-1).sum(dim=2) # weighted sum\n",
    "        else:\n",
    "            output = F.adaptive_avg_pool2d(f, (1,1)).view(N,C) # global average pooling\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a733a4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arquitetura do Modelo\n",
    "class ModeloCNN(nn.Module):\n",
    "    \n",
    "    # Pool1 = batch_size,16,50,50\n",
    "    # Pool2 = batch_size,32,44,44\n",
    "    # Pool3 = batch_size,64,20,20\n",
    "    # Pool4 = batch_size,128,14,14\n",
    "    \n",
    "    # Método construtor\n",
    "    def __init__(self):\n",
    "        super(ModeloCNN, self).__init__()\n",
    "        \n",
    "        # Camada Convolucional de entrada \n",
    "        self.conv1 = nn.Conv2d(3, 16, 4, padding = 1, stride = 2)\n",
    "        \n",
    "        # Camada MaxPooling 1\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=4, stride=2, padding=1)\n",
    "        \n",
    "        # Camada de Dropout 1 (Regularização)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        # Camada Convolucional 2 \n",
    "        self.conv2 = nn.Conv2d(16, 32, 5, padding = 1)\n",
    "        \n",
    "        # Camada MaxPooling 2\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=5, stride=1, padding=0)\n",
    "        \n",
    "        # Camada de Dropout 2 (Regularização)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        # Camada Convolucional 3 \n",
    "        self.conv3 = nn.Conv2d(32, 64, 4, padding = 1, stride = 2)\n",
    "        \n",
    "        # Camada MaxPooling 3\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=3, stride=1, padding=0)\n",
    "        \n",
    "        # Camada de Dropout 3 (Regularização)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        # Camada Convolucional 4\n",
    "        self.conv4 = nn.Conv2d(64, 128, kernel_size = 5, stride = 1, padding = 0)\n",
    "        \n",
    "        # Camada MaxPooling 4\n",
    "        self.maxpool4 = nn.MaxPool2d(kernel_size = 5, stride = 1, padding = 1)\n",
    "        \n",
    "        # Camada de Attention 1\n",
    "        self.Attn1 = AttentionLayer(in_dim1 = 32, in_dim2 = 128, attn_features = 256, normalize_attn = True, red_size = 44)\n",
    "        \n",
    "        # Camada de Attention 2\n",
    "        self.Attn2 = AttentionLayer(in_dim1 = 64, in_dim2 = 128, attn_features = 256, normalize_attn = True, red_size = 20)\n",
    "        \n",
    "        # Camada Totalmente Conectada 1\n",
    "        self.fc1 = nn.Linear(25184, 1000)\n",
    "        \n",
    "        # Camada Totalmente Conectada 2\n",
    "        self.fc2 = nn.Linear(1000, 500)\n",
    "        \n",
    "        # Camada Totalmente Conectada 3\n",
    "        self.fc3 = nn.Linear(500,4)\n",
    "    \n",
    "    # Método Forward\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Adiciona uma camada de ativação Relu para cada camada convolucional\n",
    "        pool1 = self.dropout(self.maxpool1(F.relu(self.conv1(x))))\n",
    "        pool2 = self.dropout(self.maxpool(F.relu(self.conv2(pool1))))\n",
    "        pool3 = self.dropout(self.maxpool3(F.relu(self.conv3(pool2))))\n",
    "        pool4 = self.dropout(self.maxpool4(F.relu(self.conv4(pool3))))\n",
    "        \n",
    "        N, _, _, _ = pool4.size()\n",
    "        \n",
    "        # Faz o \"achatamento\" da matriz resultante da convolução e cria um vetor\n",
    "        g = pool4.view(x.size(0), 14*14*128)\n",
    "        \n",
    "        # Camada de Attention 1\n",
    "        g1 = self.Attn1(pool2, pool4)\n",
    "        \n",
    "        # Camada de Attention 2\n",
    "        g2 = self.Attn2(pool3, pool4)\n",
    "        \n",
    "        # Concatenação dos resultados\n",
    "        g_hat = torch.cat((g, g1, g2), dim = 1) # batch_size x C\n",
    "        \n",
    "        # Adiciona uma camada de dropout para regularização\n",
    "        g_hat = self.dropout(g_hat)        \n",
    "        \n",
    "        # Camada Totalmente Conectada 1\n",
    "        out = self.fc1(g_hat)\n",
    "        \n",
    "        # Camada Totalmente Conectada 2\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        # Camada Totalmente Conectada 3 (Previsões do modelo)\n",
    "        out = self.fc3(out)        \n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1015fc30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModeloCNN(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (maxpool1): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
      "  (maxpool): MaxPool2d(kernel_size=5, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (maxpool3): MaxPool2d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv4): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (maxpool4): MaxPool2d(kernel_size=5, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "  (Attn1): AttentionLayer(\n",
      "    (W1): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (W2): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (W3): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (Attn2): AttentionLayer(\n",
      "    (W1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (W2): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (W3): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (fc1): Linear(in_features=25184, out_features=1000, bias=True)\n",
      "  (fc2): Linear(in_features=1000, out_features=500, bias=True)\n",
      "  (fc3): Linear(in_features=500, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Carregando o modelo com menor erro de validação geral, em arquivo salvo modelo_torch.pkl\n",
    "modelo_atual = pickle.load(open('modelo_torch_attn2.pkl', 'rb'))\n",
    "print(modelo_atual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4d9cbec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Erro em Teste: 0.096220\n",
      "\n",
      "Acurácia em Teste da classe glioma: 96% (290/300)\n",
      "Acurácia em Teste da classe meningioma: 96% (296/306)\n",
      "Acurácia em Teste da classe notumor: 99% (402/405)\n",
      "Acurácia em Teste da classe pituitary: 99% (299/300)\n",
      "\n",
      "Acurácia em Teste (Total): 98.17% (1287/1311)\n",
      "\n",
      "Matriz de Confusão do Modelo com Camadas de Attention:\n",
      "[[290   9   0   1]\n",
      " [  4 296   2   4]\n",
      " [  0   2 402   1]\n",
      " [  0   1   0 299]]\n",
      "\n",
      "\n",
      "CPU times: user 22.6 s, sys: 69.3 ms, total: 22.7 s\n",
      "Wall time: 4.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "torch.manual_seed(8499)\n",
    "seed(4899)\n",
    "\n",
    "prediction = torch.Tensor()\n",
    "prediction = prediction.cuda()\n",
    "y_test = torch.Tensor()\n",
    "y_test = y_test.cuda()\n",
    "\n",
    "torch.manual_seed(8499)\n",
    "seed(8499)\n",
    "\n",
    "# Lista de classes das imagens\n",
    "classes = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
    "\n",
    "# Erro em teste\n",
    "erro_teste = 0.0\n",
    "\n",
    "# Controle de acertos do modelo\n",
    "class_correct = list(0. for i in range(4))\n",
    "class_total = list(0. for i in range(4))\n",
    "\n",
    "# Inicia a avaliação do modelo\n",
    "modelo.eval()\n",
    "\n",
    "# Loop pelos batches de dados de teste\n",
    "for batch_idx, (data, target) in enumerate(test_loader):\n",
    "    \n",
    "    # Move os tensores para GPU se disponível\n",
    "    if torch.cuda.is_available():\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "        y_test = torch.cat((y_test, target), 0)\n",
    "    \n",
    "    # Forward\n",
    "    output = modelo(data)\n",
    "    \n",
    "    # Calcula o erro\n",
    "    loss = criterion(output, target)\n",
    "    \n",
    "    # Atualiza o erro em teste\n",
    "    erro_teste += loss.item() * data.size(0)\n",
    "    \n",
    "    # Converte probabilidades de saída em classe prevista\n",
    "    _, pred = torch.max(output, 1)\n",
    "    prediction = torch.cat((prediction, pred), 0)\n",
    "    \n",
    "    # Compara as previsões com o rótulo verdadeiro\n",
    "    correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not torch.cuda.is_available() else np.squeeze(correct_tensor.cpu().numpy())\n",
    "    \n",
    "    # Calcula a precisão do teste para cada classe\n",
    "    for i in range(batch_size):\n",
    "        label = target.data[i]\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] += 1\n",
    "\n",
    "# Erro médio em teste\n",
    "erro_teste = erro_teste / len(test_loader.dataset)\n",
    "print('\\nErro em Teste: {:.6f}\\n'.format(erro_teste))\n",
    "\n",
    "# Calcula a acurácia para cada classe\n",
    "for i in range(4):\n",
    "    if class_total[i] > 0:\n",
    "        print('Acurácia em Teste da classe %5s: %2d%% (%2d/%2d)' % (classes[i], \n",
    "                                                             100 * class_correct[i] / class_total[i],\n",
    "                                                             np.sum(class_correct[i]), \n",
    "                                                             np.sum(class_total[i])))\n",
    "    else:\n",
    "        print('Acurácia em Teste de %5s:)' % (classes[i]))\n",
    "\n",
    "# Calcula a acurácia total\n",
    "print('\\nAcurácia em Teste (Total): %.2f%% (%2d/%2d)' % (100. * np.sum(class_correct) / np.sum(class_total),\n",
    "                                                        np.sum(class_correct), \n",
    "                                                        np.sum(class_total)))\n",
    "\n",
    "y_test = y_test.cpu()\n",
    "prediction = prediction.cpu()\n",
    "cf_matrix = confusion_matrix(y_test, prediction)\n",
    "print(\"\\nMatriz de Confusão do Modelo com Camadas de Attention:\")\n",
    "print(cf_matrix)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ccc5bf1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas de performance do modelo com camada de attention:\n",
      "Accuracy:  0.9816933638443935\n",
      "Precision:  0.9807027231662611\n",
      "F1-Score:  0.9807124099722214\n",
      "Recall:  0.9808115468409586\n"
     ]
    }
   ],
   "source": [
    "print(\"Métricas de performance do modelo com camada de attention:\")\n",
    "print(\"Accuracy: \", accuracy_score(y_test, prediction))\n",
    "print(\"Precision: \",precision_score(y_test, prediction, average='macro'))\n",
    "print(\"F1-Score: \",f1_score(y_test, prediction, average='macro'))\n",
    "print(\"Recall: \",recall_score(y_test, prediction, average='macro'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
