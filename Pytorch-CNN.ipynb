{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1613f92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, confusion_matrix\n",
    "import seaborn as sn\n",
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "318ede88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Data Science Academy\n",
      "\n",
      "seaborn    : 0.13.2\n",
      "numpy      : 1.23.5\n",
      "torchvision: 0.16.2\n",
      "matplotlib : 3.5.2\n",
      "torch      : 2.2.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Versões dos pacotes usados neste jupyter notebook\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Data Science Academy\" --iversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "345933b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU atual: NVIDIA GeForce RTX 3060 Ti\n"
     ]
    }
   ],
   "source": [
    "# Verifica a disponibilidade do uso da GPU (RTX 3060 Ti) para o treinamento do modelo\n",
    "#!nvidia-smi\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU atual: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"Sem GPU disponível!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13a3e53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(8499)\n",
    "seed(4899)\n",
    "transform = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
    "                               transforms.RandomRotation(10),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5)),\n",
    "                               transforms.Resize([200,200])]) #128,128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6de3fc05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 5712\n",
      "    Root location: /home/ulr1c8/CUDA_related/Mestrado/Brain_Tumor_MRI_figshare+SARTAJ+Br35H/Training\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               RandomHorizontalFlip(p=0.5)\n",
      "               RandomRotation(degrees=[-10.0, 10.0], interpolation=nearest, expand=False, fill=0)\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
      "               Resize(size=[200, 200], interpolation=bilinear, max_size=None, antialias=True)\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "# Dados de Treino\n",
    "train_data = ImageFolder(root = '/home/ulr1c8/CUDA_related/Mestrado/Brain_Tumor_MRI_figshare+SARTAJ+Br35H/Training', \n",
    "                         transform=transform)\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03bac7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 1311\n",
      "    Root location: /home/ulr1c8/CUDA_related/Mestrado/Brain_Tumor_MRI_figshare+SARTAJ+Br35H/Testing\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               RandomHorizontalFlip(p=0.5)\n",
      "               RandomRotation(degrees=[-10.0, 10.0], interpolation=nearest, expand=False, fill=0)\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
      "               Resize(size=[200, 200], interpolation=bilinear, max_size=None, antialias=True)\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "# Dados de Teste\n",
    "test_data = ImageFolder(root = '/home/ulr1c8/CUDA_related/Mestrado/Brain_Tumor_MRI_figshare+SARTAJ+Br35H/Testing',\n",
    "                       transform=transform)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e116ecea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5712"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Número de amostras de treino\n",
    "num_amostras_treino = len(train_data)\n",
    "num_amostras_treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "822b5cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criamos um índice e o tornamos randômico\n",
    "torch.manual_seed(8499)\n",
    "seed(4899)\n",
    "indices = list(range(num_amostras_treino))\n",
    "np.random.shuffle(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "475242f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentual dos dados de treino que usaremos no dataset de validação\n",
    "valid_size = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19fe5848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora fazemos o split para os dados de treino e validação\n",
    "split = int(np.floor(valid_size * num_amostras_treino))\n",
    "idx_treino, idx_valid = indices[split:], indices[:split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d78ae5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos as amostras de treino\n",
    "amostras_treino = SubsetRandomSampler(idx_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f85c95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos as amostras de validação\n",
    "amostras_valid = SubsetRandomSampler(idx_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4b46fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de subprocessos para carregar os dados\n",
    "num_workers = 0\n",
    "batch_size = 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b103626f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Loader\n",
    "torch.manual_seed(8499)\n",
    "seed(4899)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, \n",
    "                                            batch_size = 28, \n",
    "                                            sampler = amostras_treino, \n",
    "                                            num_workers = num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7946495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader de dados de validação\n",
    "torch.manual_seed(8499)\n",
    "seed(4899)\n",
    "valid_loader = torch.utils.data.DataLoader(train_data, \n",
    "                                           batch_size = 28, \n",
    "                                           sampler = amostras_valid, \n",
    "                                           num_workers = num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d071aead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Loader\n",
    "torch.manual_seed(8499)\n",
    "seed(4899)\n",
    "test_loader = torch.utils.data.DataLoader(test_data,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ede3c386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arquitetura do Modelo\n",
    "class ModeloCNN(nn.Module):\n",
    "    \n",
    "    # Método construtor\n",
    "    def __init__(self):\n",
    "        super(ModeloCNN, self).__init__()\n",
    "        \n",
    "        # Camada Convolucional de entrada \n",
    "        self.conv1 = nn.Conv2d(3, 16, 4, padding = 1, stride = 2)\n",
    "        \n",
    "        # Camada MaxPooling 1\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=4, stride=2, padding=1)\n",
    "        \n",
    "        # Camada de Dropout 1 (Regularização)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        # Camada Convolucional oculta \n",
    "        self.conv2 = nn.Conv2d(16, 32, 5, padding = 1)\n",
    "        \n",
    "        # Camada MaxPooling 2\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=5, stride=1, padding=0)\n",
    "        \n",
    "        # Camada de Dropout 2 (Regularização)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        # Camada Convolucional oculta \n",
    "        self.conv3 = nn.Conv2d(32, 64, 4, padding = 1, stride = 2)\n",
    "        \n",
    "        # Camada MaxPooling 3\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=3, stride=1, padding=0)\n",
    "        \n",
    "        # Camada de Dropout 4 (Regularização)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        # Camada Totalmente Conectada 1\n",
    "        self.fc1 = nn.Linear(20*20*64, 1000)\n",
    "        \n",
    "        # Camada totalmente Conectada 2\n",
    "        self.fc2 = nn.Linear(1000,500)\n",
    "        \n",
    "        # Camada Totalmente Conectada 3\n",
    "        self.fc3 = nn.Linear(500, 4)\n",
    "    \n",
    "    # Método Forward\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Adiciona uma camada de ativação Relu para cada camada convolucional\n",
    "        x = self.dropout(self.maxpool1(F.relu(self.conv1(x))))\n",
    "        x = self.dropout(self.maxpool2(F.relu(self.conv2(x))))\n",
    "        x = self.dropout(self.maxpool3(F.relu(self.conv3(x))))\n",
    "        \n",
    "        # Faz o \"achatamento\" da matriz resultante da convolução e cria um vetor\n",
    "        x = x.view(x.size(0), 20*20*64)\n",
    "        \n",
    "        # Adiciona uma camada de dropout para regularização\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Adiciona a 1ª camada oculta, com função de ativação relu\n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        # Adiciona a 2ª camada oculta\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        # Adiciona a 3ª camada oculta (classificação feita pelo modelo)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1dc68a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModeloCNN(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (maxpool1): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
      "  (maxpool2): MaxPool2d(kernel_size=5, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (maxpool3): MaxPool2d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=25600, out_features=1000, bias=True)\n",
      "  (fc2): Linear(in_features=1000, out_features=500, bias=True)\n",
      "  (fc3): Linear(in_features=500, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Cria o modelo\n",
    "modelo = ModeloCNN()\n",
    "print(modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9fa4406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Movemos o modelo para a GPU se disponível\n",
    "if torch.cuda.is_available():\n",
    "    modelo.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70834f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função perda como categorical cross-entropy\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "91798b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiperparâmetro taxa de aprendizado\n",
    "lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce91bbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otimizador\n",
    "optimizer = optim.Adam(modelo.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8515e193",
   "metadata": {},
   "source": [
    "## Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a18d502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de épocas para treinar o modelo\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "436ceffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiperparametro para controlar a mudança do erro em validação\n",
    "erro_valid_min = np.Inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "75104df6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60066b1f",
   "metadata": {},
   "source": [
    "### Treinamento do modelo (a execução pode demorar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9494f6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1 \tErro em Treinamento: 0.802672 \tErro em Validação: 0.230151\n",
      "Erro em Validação foi Reduzido (inf --> 0.230151). Salvando o modelo...\n",
      "\n",
      "Epoch: 2 \tErro em Treinamento: 0.533509 \tErro em Validação: 0.197814\n",
      "Erro em Validação foi Reduzido (0.230151 --> 0.197814). Salvando o modelo...\n",
      "\n",
      "Epoch: 3 \tErro em Treinamento: 0.467951 \tErro em Validação: 0.192418\n",
      "Erro em Validação foi Reduzido (0.197814 --> 0.192418). Salvando o modelo...\n",
      "\n",
      "Epoch: 4 \tErro em Treinamento: 0.410031 \tErro em Validação: 0.167634\n",
      "Erro em Validação foi Reduzido (0.192418 --> 0.167634). Salvando o modelo...\n",
      "\n",
      "Epoch: 5 \tErro em Treinamento: 0.377079 \tErro em Validação: 0.167910\n",
      "\n",
      "Epoch: 6 \tErro em Treinamento: 0.351820 \tErro em Validação: 0.139635\n",
      "Erro em Validação foi Reduzido (0.167634 --> 0.139635). Salvando o modelo...\n",
      "\n",
      "Epoch: 7 \tErro em Treinamento: 0.324680 \tErro em Validação: 0.148075\n",
      "\n",
      "Epoch: 8 \tErro em Treinamento: 0.307797 \tErro em Validação: 0.136795\n",
      "Erro em Validação foi Reduzido (0.139635 --> 0.136795). Salvando o modelo...\n",
      "\n",
      "Epoch: 9 \tErro em Treinamento: 0.287472 \tErro em Validação: 0.154677\n",
      "\n",
      "Epoch: 10 \tErro em Treinamento: 0.268890 \tErro em Validação: 0.126842\n",
      "Erro em Validação foi Reduzido (0.136795 --> 0.126842). Salvando o modelo...\n",
      "\n",
      "Epoch: 11 \tErro em Treinamento: 0.243008 \tErro em Validação: 0.120228\n",
      "Erro em Validação foi Reduzido (0.126842 --> 0.120228). Salvando o modelo...\n",
      "\n",
      "Epoch: 12 \tErro em Treinamento: 0.236141 \tErro em Validação: 0.107608\n",
      "Erro em Validação foi Reduzido (0.120228 --> 0.107608). Salvando o modelo...\n",
      "\n",
      "Epoch: 13 \tErro em Treinamento: 0.216590 \tErro em Validação: 0.103223\n",
      "Erro em Validação foi Reduzido (0.107608 --> 0.103223). Salvando o modelo...\n",
      "\n",
      "Epoch: 14 \tErro em Treinamento: 0.207001 \tErro em Validação: 0.094459\n",
      "Erro em Validação foi Reduzido (0.103223 --> 0.094459). Salvando o modelo...\n",
      "\n",
      "Epoch: 15 \tErro em Treinamento: 0.184607 \tErro em Validação: 0.090448\n",
      "Erro em Validação foi Reduzido (0.094459 --> 0.090448). Salvando o modelo...\n",
      "\n",
      "Epoch: 16 \tErro em Treinamento: 0.184207 \tErro em Validação: 0.092982\n",
      "\n",
      "Epoch: 17 \tErro em Treinamento: 0.159991 \tErro em Validação: 0.075455\n",
      "Erro em Validação foi Reduzido (0.090448 --> 0.075455). Salvando o modelo...\n",
      "\n",
      "Epoch: 18 \tErro em Treinamento: 0.143986 \tErro em Validação: 0.075482\n",
      "\n",
      "Epoch: 19 \tErro em Treinamento: 0.145426 \tErro em Validação: 0.085914\n",
      "\n",
      "Epoch: 20 \tErro em Treinamento: 0.135874 \tErro em Validação: 0.070016\n",
      "Erro em Validação foi Reduzido (0.075455 --> 0.070016). Salvando o modelo...\n",
      "\n",
      "Epoch: 21 \tErro em Treinamento: 0.130710 \tErro em Validação: 0.067016\n",
      "Erro em Validação foi Reduzido (0.070016 --> 0.067016). Salvando o modelo...\n",
      "\n",
      "Epoch: 22 \tErro em Treinamento: 0.107800 \tErro em Validação: 0.079456\n",
      "\n",
      "Epoch: 23 \tErro em Treinamento: 0.115814 \tErro em Validação: 0.062898\n",
      "Erro em Validação foi Reduzido (0.067016 --> 0.062898). Salvando o modelo...\n",
      "\n",
      "Epoch: 24 \tErro em Treinamento: 0.106213 \tErro em Validação: 0.056871\n",
      "Erro em Validação foi Reduzido (0.062898 --> 0.056871). Salvando o modelo...\n",
      "\n",
      "Epoch: 25 \tErro em Treinamento: 0.099921 \tErro em Validação: 0.059076\n",
      "\n",
      "Epoch: 26 \tErro em Treinamento: 0.089915 \tErro em Validação: 0.064694\n",
      "\n",
      "Epoch: 27 \tErro em Treinamento: 0.092917 \tErro em Validação: 0.054913\n",
      "Erro em Validação foi Reduzido (0.056871 --> 0.054913). Salvando o modelo...\n",
      "\n",
      "Epoch: 28 \tErro em Treinamento: 0.084505 \tErro em Validação: 0.059047\n",
      "\n",
      "Epoch: 29 \tErro em Treinamento: 0.077761 \tErro em Validação: 0.047840\n",
      "Erro em Validação foi Reduzido (0.054913 --> 0.047840). Salvando o modelo...\n",
      "\n",
      "Epoch: 30 \tErro em Treinamento: 0.073167 \tErro em Validação: 0.051412\n",
      "\n",
      "Epoch: 31 \tErro em Treinamento: 0.072481 \tErro em Validação: 0.042798\n",
      "Erro em Validação foi Reduzido (0.047840 --> 0.042798). Salvando o modelo...\n",
      "\n",
      "Epoch: 32 \tErro em Treinamento: 0.061473 \tErro em Validação: 0.044650\n",
      "\n",
      "Epoch: 33 \tErro em Treinamento: 0.058129 \tErro em Validação: 0.042889\n",
      "\n",
      "Epoch: 34 \tErro em Treinamento: 0.062615 \tErro em Validação: 0.055759\n",
      "\n",
      "Epoch: 35 \tErro em Treinamento: 0.061626 \tErro em Validação: 0.042054\n",
      "Erro em Validação foi Reduzido (0.042798 --> 0.042054). Salvando o modelo...\n",
      "\n",
      "Epoch: 36 \tErro em Treinamento: 0.061117 \tErro em Validação: 0.041488\n",
      "Erro em Validação foi Reduzido (0.042054 --> 0.041488). Salvando o modelo...\n",
      "\n",
      "Epoch: 37 \tErro em Treinamento: 0.058740 \tErro em Validação: 0.036284\n",
      "Erro em Validação foi Reduzido (0.041488 --> 0.036284). Salvando o modelo...\n",
      "\n",
      "Epoch: 38 \tErro em Treinamento: 0.045413 \tErro em Validação: 0.040965\n",
      "\n",
      "Epoch: 39 \tErro em Treinamento: 0.047579 \tErro em Validação: 0.036778\n",
      "\n",
      "Epoch: 40 \tErro em Treinamento: 0.049257 \tErro em Validação: 0.040224\n",
      "\n",
      "Epoch: 41 \tErro em Treinamento: 0.036789 \tErro em Validação: 0.035636\n",
      "Erro em Validação foi Reduzido (0.036284 --> 0.035636). Salvando o modelo...\n",
      "\n",
      "Epoch: 42 \tErro em Treinamento: 0.037345 \tErro em Validação: 0.036527\n",
      "\n",
      "Epoch: 43 \tErro em Treinamento: 0.046180 \tErro em Validação: 0.059062\n",
      "\n",
      "Epoch: 44 \tErro em Treinamento: 0.035800 \tErro em Validação: 0.043965\n",
      "\n",
      "Epoch: 45 \tErro em Treinamento: 0.037181 \tErro em Validação: 0.040772\n",
      "\n",
      "Epoch: 46 \tErro em Treinamento: 0.031713 \tErro em Validação: 0.034517\n",
      "Erro em Validação foi Reduzido (0.035636 --> 0.034517). Salvando o modelo...\n",
      "\n",
      "Epoch: 47 \tErro em Treinamento: 0.033386 \tErro em Validação: 0.034226\n",
      "Erro em Validação foi Reduzido (0.034517 --> 0.034226). Salvando o modelo...\n",
      "\n",
      "Epoch: 48 \tErro em Treinamento: 0.029445 \tErro em Validação: 0.056042\n",
      "\n",
      "Epoch: 49 \tErro em Treinamento: 0.037493 \tErro em Validação: 0.043654\n",
      "\n",
      "Epoch: 50 \tErro em Treinamento: 0.028157 \tErro em Validação: 0.039464\n",
      "\n",
      "Epoch: 51 \tErro em Treinamento: 0.028486 \tErro em Validação: 0.032035\n",
      "Erro em Validação foi Reduzido (0.034226 --> 0.032035). Salvando o modelo...\n",
      "\n",
      "Epoch: 52 \tErro em Treinamento: 0.026202 \tErro em Validação: 0.042819\n",
      "\n",
      "Epoch: 53 \tErro em Treinamento: 0.033530 \tErro em Validação: 0.031773\n",
      "Erro em Validação foi Reduzido (0.032035 --> 0.031773). Salvando o modelo...\n",
      "\n",
      "Epoch: 54 \tErro em Treinamento: 0.022546 \tErro em Validação: 0.037270\n",
      "\n",
      "Epoch: 55 \tErro em Treinamento: 0.023451 \tErro em Validação: 0.029871\n",
      "Erro em Validação foi Reduzido (0.031773 --> 0.029871). Salvando o modelo...\n",
      "\n",
      "Epoch: 56 \tErro em Treinamento: 0.031509 \tErro em Validação: 0.035127\n",
      "\n",
      "Epoch: 57 \tErro em Treinamento: 0.024475 \tErro em Validação: 0.033900\n",
      "\n",
      "Epoch: 58 \tErro em Treinamento: 0.018100 \tErro em Validação: 0.035294\n",
      "\n",
      "Epoch: 59 \tErro em Treinamento: 0.016614 \tErro em Validação: 0.029628\n",
      "Erro em Validação foi Reduzido (0.029871 --> 0.029628). Salvando o modelo...\n",
      "\n",
      "Epoch: 60 \tErro em Treinamento: 0.025230 \tErro em Validação: 0.032431\n",
      "\n",
      "Epoch: 61 \tErro em Treinamento: 0.020891 \tErro em Validação: 0.031786\n",
      "\n",
      "Epoch: 62 \tErro em Treinamento: 0.014179 \tErro em Validação: 0.033703\n",
      "\n",
      "Epoch: 63 \tErro em Treinamento: 0.030641 \tErro em Validação: 0.030407\n",
      "\n",
      "Epoch: 64 \tErro em Treinamento: 0.019637 \tErro em Validação: 0.042395\n",
      "\n",
      "Epoch: 65 \tErro em Treinamento: 0.015474 \tErro em Validação: 0.039329\n",
      "\n",
      "Epoch: 66 \tErro em Treinamento: 0.015163 \tErro em Validação: 0.044359\n",
      "\n",
      "Epoch: 67 \tErro em Treinamento: 0.011596 \tErro em Validação: 0.033698\n",
      "\n",
      "Epoch: 68 \tErro em Treinamento: 0.020059 \tErro em Validação: 0.039521\n",
      "\n",
      "Epoch: 69 \tErro em Treinamento: 0.016932 \tErro em Validação: 0.031854\n",
      "\n",
      "Epoch: 70 \tErro em Treinamento: 0.021172 \tErro em Validação: 0.035207\n",
      "\n",
      "Epoch: 71 \tErro em Treinamento: 0.010254 \tErro em Validação: 0.034200\n",
      "\n",
      "Epoch: 72 \tErro em Treinamento: 0.018268 \tErro em Validação: 0.037554\n",
      "\n",
      "Epoch: 73 \tErro em Treinamento: 0.014025 \tErro em Validação: 0.037685\n",
      "\n",
      "Epoch: 74 \tErro em Treinamento: 0.014148 \tErro em Validação: 0.035774\n",
      "\n",
      "Epoch: 75 \tErro em Treinamento: 0.013034 \tErro em Validação: 0.039063\n",
      "\n",
      "Epoch: 76 \tErro em Treinamento: 0.020556 \tErro em Validação: 0.042441\n",
      "\n",
      "Epoch: 77 \tErro em Treinamento: 0.022913 \tErro em Validação: 0.039860\n",
      "\n",
      "Epoch: 78 \tErro em Treinamento: 0.013342 \tErro em Validação: 0.033989\n",
      "\n",
      "Epoch: 79 \tErro em Treinamento: 0.010546 \tErro em Validação: 0.045160\n",
      "\n",
      "Epoch: 80 \tErro em Treinamento: 0.012020 \tErro em Validação: 0.038589\n",
      "\n",
      "Epoch: 81 \tErro em Treinamento: 0.016089 \tErro em Validação: 0.040569\n",
      "\n",
      "Epoch: 82 \tErro em Treinamento: 0.017056 \tErro em Validação: 0.036410\n",
      "\n",
      "Epoch: 83 \tErro em Treinamento: 0.007768 \tErro em Validação: 0.033528\n",
      "\n",
      "Epoch: 84 \tErro em Treinamento: 0.008382 \tErro em Validação: 0.040940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 85 \tErro em Treinamento: 0.010578 \tErro em Validação: 0.038004\n",
      "\n",
      "Epoch: 86 \tErro em Treinamento: 0.007743 \tErro em Validação: 0.043926\n",
      "\n",
      "Epoch: 87 \tErro em Treinamento: 0.010211 \tErro em Validação: 0.039407\n",
      "\n",
      "Epoch: 88 \tErro em Treinamento: 0.018182 \tErro em Validação: 0.034590\n",
      "\n",
      "Epoch: 89 \tErro em Treinamento: 0.011389 \tErro em Validação: 0.042993\n",
      "\n",
      "Epoch: 90 \tErro em Treinamento: 0.011007 \tErro em Validação: 0.042973\n",
      "\n",
      "Epoch: 91 \tErro em Treinamento: 0.008699 \tErro em Validação: 0.041093\n",
      "\n",
      "Epoch: 92 \tErro em Treinamento: 0.013986 \tErro em Validação: 0.042917\n",
      "\n",
      "Epoch: 93 \tErro em Treinamento: 0.010560 \tErro em Validação: 0.033715\n",
      "\n",
      "Epoch: 94 \tErro em Treinamento: 0.015212 \tErro em Validação: 0.049924\n",
      "\n",
      "Epoch: 95 \tErro em Treinamento: 0.012855 \tErro em Validação: 0.044194\n",
      "\n",
      "Epoch: 96 \tErro em Treinamento: 0.011801 \tErro em Validação: 0.052602\n",
      "\n",
      "Epoch: 97 \tErro em Treinamento: 0.011188 \tErro em Validação: 0.029394\n",
      "Erro em Validação foi Reduzido (0.029628 --> 0.029394). Salvando o modelo...\n",
      "\n",
      "Epoch: 98 \tErro em Treinamento: 0.011054 \tErro em Validação: 0.039180\n",
      "\n",
      "Epoch: 99 \tErro em Treinamento: 0.008772 \tErro em Validação: 0.037530\n",
      "\n",
      "Epoch: 100 \tErro em Treinamento: 0.008132 \tErro em Validação: 0.035590\n",
      "CPU times: user 2h 58min 34s, sys: 43.6 s, total: 2h 59min 17s\n",
      "Wall time: 27min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "torch.manual_seed(8499)\n",
    "seed(4899)\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "\n",
    "    # Parâmetros para acompanhar o erro total em treinamento e validação\n",
    "    erro_treino = 0.0\n",
    "    erro_valid = 0.0\n",
    "    \n",
    "    # Inicia o treinamento do modelo\n",
    "    modelo.train().to(\"cuda\")\n",
    "    \n",
    "    # Loop pelos batches de dados de treino\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        \n",
    "        # Move os tensores para a GPU se disponível\n",
    "        if torch.cuda.is_available():\n",
    "            data, target = data.to(\"cuda\"), target.to(\"cuda\")\n",
    "        \n",
    "        # Limpa os gradientes de todas as variáveis otimizadas\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward: calcula as saídas previstas\n",
    "        output = modelo(data)\n",
    "        \n",
    "        # Calcula o erro no batch\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        # Backward: calcula o gradiente da perda em relação aos parâmetros do modelo\n",
    "        loss.backward()\n",
    "        \n",
    "        # Realiza uma única etapa de otimização (atualização dos parâmetros)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Atualiza o erro total em treino\n",
    "        erro_treino += loss.item() * data.size(0)\n",
    "        \n",
    "    # Inicia a validação do modelo\n",
    "    modelo.eval().cuda\n",
    "    \n",
    "    # Loop pelos batches de dados de validação\n",
    "    for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "        \n",
    "        # Move os tensores para a GPU se disponível\n",
    "        if torch.cuda.is_available():\n",
    "            data, target = data.to(\"cuda\"), target.to(\"cuda\")\n",
    "        \n",
    "        # Forward: calcula as saídas previstas\n",
    "        output = modelo(data)\n",
    "        \n",
    "        # Calcula o erro no batch\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        # Atualiza o erro total de validação\n",
    "        erro_valid += loss.item() * data.size(0)\n",
    "    \n",
    "    # Calcula o erro médio\n",
    "    erro_treino = erro_treino / len(train_loader.dataset)\n",
    "    erro_valid = erro_valid / len(valid_loader.dataset)\n",
    "        \n",
    "    # Print\n",
    "    print('\\nEpoch: {} \\tErro em Treinamento: {:.6f} \\tErro em Validação: {:.6f}'.format(epoch, \n",
    "                                                                                         erro_treino, \n",
    "                                                                                         erro_valid))\n",
    "    \n",
    "    # Salva o modelo sempre que a perda em validação diminuir\n",
    "    if erro_valid <= erro_valid_min:\n",
    "        print('Erro em Validação foi Reduzido ({:.6f} --> {:.6f}). Salvando o modelo...'.format(erro_valid_min,\n",
    "                                                                                                 erro_valid))\n",
    "        #pickle.dump(modelo, open('modelo_torch2.pkl', 'wb'))\n",
    "        erro_valid_min = erro_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ded4b45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o modelo com menor erro de validação após treinamanto\n",
    "modelo = pickle.load(open('modelo_torch2.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b77a2c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Só usar caso a acurácia do modelo testado seja maior que a acurácia atual do arquivo modelo_torch.pkl\n",
    "#pickle.dump(modelo, open('modelo_torch.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1015fc30",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModeloCNN(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (maxpool1): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
      "  (maxpool2): MaxPool2d(kernel_size=5, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (maxpool3): MaxPool2d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=25600, out_features=1000, bias=True)\n",
      "  (fc2): Linear(in_features=1000, out_features=500, bias=True)\n",
      "  (fc3): Linear(in_features=500, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Carregando o modelo com menor erro de validação geral, em arquivo salvo modelo_torch.pkl\n",
    "modelo_atual = pickle.load(open('modelo_torch.pkl', 'rb'))\n",
    "print(modelo_atual)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1c9aac",
   "metadata": {},
   "source": [
    "### Testando e Avaliando o Modelo Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "19484801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de classes das imagens\n",
    "classes = ['glioma', 'meningioma', 'notumor', 'pituitary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "104fafb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erro em teste\n",
    "erro_teste = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f453478a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Controle de acertos do modelo\n",
    "class_correct = list(0. for i in range(4))\n",
    "class_total = list(0. for i in range(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c1f89bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Erro em Teste: 0.108381\n",
      "\n",
      "Acurácia em Teste da classe glioma: 94% (284/300)\n",
      "Acurácia em Teste da classe meningioma: 93% (285/306)\n",
      "Acurácia em Teste da classe notumor: 99% (404/405)\n",
      "Acurácia em Teste da classe pituitary: 99% (299/300)\n",
      "\n",
      "Acurácia em Teste (Total): 97.03% (1272/1311)\n",
      "\n",
      "Matriz de Confusão do Modelo com Camadas de Attention:\n",
      "[[284  13   1   2]\n",
      " [  9 285   7   5]\n",
      " [  0   1 404   0]\n",
      " [  0   1   0 299]]\n",
      "\n",
      "\n",
      "CPU times: user 22.8 s, sys: 307 ms, total: 23.1 s\n",
      "Wall time: 4.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "torch.manual_seed(8499)\n",
    "seed(4899)\n",
    "\n",
    "prediction = torch.Tensor()\n",
    "prediction = prediction.cuda()\n",
    "y_test = torch.Tensor()\n",
    "y_test = y_test.cuda()\n",
    "\n",
    "torch.manual_seed(8499)\n",
    "seed(8499)\n",
    "\n",
    "# Lista de classes das imagens\n",
    "classes = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
    "\n",
    "# Erro em teste\n",
    "erro_teste = 0.0\n",
    "\n",
    "# Controle de acertos do modelo\n",
    "class_correct = list(0. for i in range(4))\n",
    "class_total = list(0. for i in range(4))\n",
    "\n",
    "# Inicia a avaliação do modelo\n",
    "modelo.eval()\n",
    "\n",
    "# Loop pelos batches de dados de teste\n",
    "for batch_idx, (data, target) in enumerate(test_loader):\n",
    "    \n",
    "    # Move os tensores para GPU se disponível\n",
    "    if torch.cuda.is_available():\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "        y_test = torch.cat((y_test, target), 0)\n",
    "    \n",
    "    # Forward\n",
    "    output = modelo(data)\n",
    "    \n",
    "    # Calcula o erro\n",
    "    loss = criterion(output, target)\n",
    "    \n",
    "    # Atualiza o erro em teste\n",
    "    erro_teste += loss.item() * data.size(0)\n",
    "    \n",
    "    # Converte probabilidades de saída em classe prevista\n",
    "    _, pred = torch.max(output, 1)\n",
    "    prediction = torch.cat((prediction, pred), 0)\n",
    "    \n",
    "    # Compara as previsões com o rótulo verdadeiro\n",
    "    correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not torch.cuda.is_available() else np.squeeze(correct_tensor.cpu().numpy())\n",
    "    \n",
    "    # Calcula a precisão do teste para cada classe\n",
    "    for i in range(batch_size):\n",
    "        label = target.data[i]\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] += 1\n",
    "\n",
    "# Erro médio em teste\n",
    "erro_teste = erro_teste / len(test_loader.dataset)\n",
    "print('\\nErro em Teste: {:.6f}\\n'.format(erro_teste))\n",
    "\n",
    "# Calcula a acurácia para cada classe\n",
    "for i in range(4):\n",
    "    if class_total[i] > 0:\n",
    "        print('Acurácia em Teste da classe %5s: %2d%% (%2d/%2d)' % (classes[i], \n",
    "                                                             100 * class_correct[i] / class_total[i],\n",
    "                                                             np.sum(class_correct[i]), \n",
    "                                                             np.sum(class_total[i])))\n",
    "    else:\n",
    "        print('Acurácia em Teste de %5s:)' % (classes[i]))\n",
    "\n",
    "# Calcula a acurácia total\n",
    "print('\\nAcurácia em Teste (Total): %.2f%% (%2d/%2d)' % (100. * np.sum(class_correct) / np.sum(class_total),\n",
    "                                                        np.sum(class_correct), \n",
    "                                                        np.sum(class_total)))\n",
    "\n",
    "y_test = y_test.cpu()\n",
    "prediction = prediction.cpu()\n",
    "cf_matrix = confusion_matrix(y_test, prediction)\n",
    "print(\"\\nMatriz de Confusão do Modelo com Camadas de Attention:\")\n",
    "print(cf_matrix)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7a2d022a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas de performance do modelo com camada de attention:\n",
      "Accuracy:  0.9702517162471396\n",
      "Precision:  0.9692474959322231\n",
      "F1-Score:  0.9685545778452467\n",
      "Recall:  0.9680591866376179\n"
     ]
    }
   ],
   "source": [
    "print(\"Métricas de performance do modelo com camada de attention:\")\n",
    "print(\"Accuracy: \", accuracy_score(y_test, prediction))\n",
    "print(\"Precision: \",precision_score(y_test, prediction, average='macro'))\n",
    "print(\"F1-Score: \",f1_score(y_test, prediction, average='macro'))\n",
    "print(\"Recall: \",recall_score(y_test, prediction, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797b01c7",
   "metadata": {},
   "source": [
    "# Melhor modelo até agora (modelo_atual - modelo_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3a536d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arquitetura do Modelo\n",
    "class ModeloCNN(nn.Module):\n",
    "    \n",
    "    # Método construtor\n",
    "    def __init__(self):\n",
    "        super(ModeloCNN, self).__init__()\n",
    "        \n",
    "        # Camada Convolucional de entrada \n",
    "        self.conv1 = nn.Conv2d(3, 16, 4, padding = 1, stride = 2)\n",
    "        \n",
    "        # Camada MaxPooling 1\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=4, stride=2, padding=1)\n",
    "        \n",
    "        # Camada de Dropout 1 (Regularização)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        # Camada Convolucional oculta \n",
    "        self.conv2 = nn.Conv2d(16, 32, 5, padding = 1)\n",
    "        \n",
    "        # Camada MaxPooling 2\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=5, stride=1, padding=0)\n",
    "        \n",
    "        # Camada de Dropout 2 (Regularização)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        # Camada Convolucional oculta \n",
    "        self.conv3 = nn.Conv2d(32, 64, 4, padding = 1, stride = 2)\n",
    "        \n",
    "        # Camada MaxPooling 3\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=3, stride=1, padding=0)\n",
    "        \n",
    "        # Camada de Dropout 4 (Regularização)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        # Camada Totalmente Conectada 1\n",
    "        self.fc1 = nn.Linear(20*20*64, 1000)\n",
    "        \n",
    "        # Camada totalmente Conectada 2\n",
    "        self.fc2 = nn.Linear(1000,500)\n",
    "        \n",
    "        # Camada Totalmente Conectada 3\n",
    "        self.fc3 = nn.Linear(500, 4)\n",
    "    \n",
    "    # Método Forward\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Adiciona uma camada de ativação Relu para cada camada convolucional\n",
    "        x = self.dropout(self.maxpool1(F.relu(self.conv1(x))))\n",
    "        x = self.dropout(self.maxpool2(F.relu(self.conv2(x))))\n",
    "        x = self.dropout(self.maxpool3(F.relu(self.conv3(x))))\n",
    "        \n",
    "        # Faz o \"achatamento\" da matriz resultante da convolução e cria um vetor\n",
    "        x = x.view(x.size(0), 20*20*64)\n",
    "        \n",
    "        # Adiciona uma camada de dropout para regularização\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Adiciona a 1ª camada oculta, com função de ativação relu\n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        # Adiciona a 2ª camada oculta\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        # Adiciona a 3ª camada oculta (classificação feita pelo modelo)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4d8670ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModeloCNN(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (maxpool1): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
      "  (maxpool2): MaxPool2d(kernel_size=5, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (maxpool3): MaxPool2d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=25600, out_features=1000, bias=True)\n",
      "  (fc2): Linear(in_features=1000, out_features=500, bias=True)\n",
      "  (fc3): Linear(in_features=500, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Carregando o modelo com menor erro de validação geral, em arquivo salvo modelo_torch.pkl\n",
    "modelo_atual = pickle.load(open('modelo_torch.pkl', 'rb'))\n",
    "print(modelo_atual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "eef4073c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Erro em Teste: 0.121649\n",
      "\n",
      "Acurácia em Teste da classe glioma: 93% (280/300)\n",
      "Acurácia em Teste da classe meningioma: 93% (286/306)\n",
      "Acurácia em Teste da classe notumor: 100% (405/405)\n",
      "Acurácia em Teste da classe pituitary: 99% (298/300)\n",
      "\n",
      "Acurácia em Teste (Total): 96.80% (1269/1311)\n",
      "\n",
      "Matriz de Confusão do Modelo com Camadas de Attention:\n",
      "[[280  18   0   2]\n",
      " [  7 286   6   7]\n",
      " [  0   0 405   0]\n",
      " [  0   2   0 298]]\n",
      "\n",
      "\n",
      "CPU times: user 22.1 s, sys: 110 ms, total: 22.3 s\n",
      "Wall time: 3.42 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "torch.manual_seed(8499)\n",
    "seed(4899)\n",
    "\n",
    "prediction = torch.Tensor()\n",
    "prediction = prediction.cuda()\n",
    "y_test = torch.Tensor()\n",
    "y_test = y_test.cuda()\n",
    "\n",
    "torch.manual_seed(8499)\n",
    "seed(8499)\n",
    "\n",
    "# Lista de classes das imagens\n",
    "classes = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
    "\n",
    "# Erro em teste\n",
    "erro_teste = 0.0\n",
    "\n",
    "# Controle de acertos do modelo\n",
    "class_correct = list(0. for i in range(4))\n",
    "class_total = list(0. for i in range(4))\n",
    "\n",
    "# Inicia a avaliação do modelo\n",
    "modelo_atual.eval()\n",
    "\n",
    "# Loop pelos batches de dados de teste\n",
    "for batch_idx, (data, target) in enumerate(test_loader):\n",
    "    \n",
    "    # Move os tensores para GPU se disponível\n",
    "    if torch.cuda.is_available():\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "        y_test = torch.cat((y_test, target), 0)\n",
    "    \n",
    "    # Forward\n",
    "    output = modelo_atual(data)\n",
    "    \n",
    "    # Calcula o erro\n",
    "    loss = criterion(output, target)\n",
    "    \n",
    "    # Atualiza o erro em teste\n",
    "    erro_teste += loss.item() * data.size(0)\n",
    "    \n",
    "    # Converte probabilidades de saída em classe prevista\n",
    "    _, pred = torch.max(output, 1)\n",
    "    prediction = torch.cat((prediction, pred), 0)\n",
    "    \n",
    "    # Compara as previsões com o rótulo verdadeiro\n",
    "    correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not torch.cuda.is_available() else np.squeeze(correct_tensor.cpu().numpy())\n",
    "    \n",
    "    # Calcula a precisão do teste para cada classe\n",
    "    for i in range(batch_size):\n",
    "        label = target.data[i]\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] += 1\n",
    "\n",
    "# Erro médio em teste\n",
    "erro_teste = erro_teste / len(test_loader.dataset)\n",
    "print('\\nErro em Teste: {:.6f}\\n'.format(erro_teste))\n",
    "\n",
    "# Calcula a acurácia para cada classe\n",
    "for i in range(4):\n",
    "    if class_total[i] > 0:\n",
    "        print('Acurácia em Teste da classe %5s: %2d%% (%2d/%2d)' % (classes[i], \n",
    "                                                             100 * class_correct[i] / class_total[i],\n",
    "                                                             np.sum(class_correct[i]), \n",
    "                                                             np.sum(class_total[i])))\n",
    "    else:\n",
    "        print('Acurácia em Teste de %5s:)' % (classes[i]))\n",
    "\n",
    "# Calcula a acurácia total\n",
    "print('\\nAcurácia em Teste (Total): %.2f%% (%2d/%2d)' % (100. * np.sum(class_correct) / np.sum(class_total),\n",
    "                                                        np.sum(class_correct), \n",
    "                                                        np.sum(class_total)))\n",
    "y_test = y_test.cpu()\n",
    "prediction = prediction.cpu()\n",
    "cf_matrix = confusion_matrix(y_test, prediction)\n",
    "print(\"\\nMatriz de Confusão do Modelo com Camadas de Attention:\")\n",
    "print(cf_matrix)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60af7e01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
